{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb04f1a2-1f87-42e6-a5ad-453eec40215f",
   "metadata": {},
   "source": [
    "# Models API\n",
    "\n",
    "使用 Models API 查看和访问 OpenAI 提供的预训练大语言模型\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7466990e-c2ac-441c-a545-fdc122e752ca",
   "metadata": {},
   "source": [
    "## List Models\n",
    "\n",
    "列出当前可用的模型，并提供每个模型的基本信息，如所有者和可用性。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f453ab0c-b262-4fa5-993e-b4b341e46a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "client = OpenAI(base_url=\"https://aihubmix.com/v1\")\n",
    "\n",
    "models = client.models.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87dbc132-41cd-4ebc-928f-9edf6a4befcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SyncPage[Model](data=[Model(id='gpt-3.5-turbo-1106', created=1698959748, object='model', owned_by='system'), Model(id='dall-e-3', created=1698785189, object='model', owned_by='system'), Model(id='gpt-4-0613', created=1686588896, object='model', owned_by='openai'), Model(id='dall-e-2', created=1698798177, object='model', owned_by='system'), Model(id='gpt-3.5-turbo-0125', created=1706048358, object='model', owned_by='system'), Model(id='gpt-4', created=1687882411, object='model', owned_by='openai'), Model(id='whisper-1', created=1677532384, object='model', owned_by='openai-internal'), Model(id='tts-1-hd-1106', created=1699053533, object='model', owned_by='system'), Model(id='gpt-3.5-turbo', created=1677610602, object='model', owned_by='openai'), Model(id='tts-1-hd', created=1699046015, object='model', owned_by='system'), Model(id='gpt-4-0125-preview', created=1706037612, object='model', owned_by='system'), Model(id='gpt-4-turbo-preview', created=1706037777, object='model', owned_by='system'), Model(id='text-embedding-3-large', created=1705953180, object='model', owned_by='system'), Model(id='gpt-3.5-turbo-0301', created=1677649963, object='model', owned_by='openai'), Model(id='gpt-3.5-turbo-0613', created=1686587434, object='model', owned_by='openai'), Model(id='gpt-4-vision-preview', created=1698894917, object='model', owned_by='system'), Model(id='gpt-3.5-turbo-16k-0613', created=1685474247, object='model', owned_by='openai'), Model(id='gpt-3.5-turbo-16k', created=1683758102, object='model', owned_by='openai-internal'), Model(id='gpt-4-1106-preview', created=1698957206, object='model', owned_by='system'), Model(id='gpt-3.5-turbo-instruct', created=1692901427, object='model', owned_by='system'), Model(id='gpt-3.5-turbo-instruct-0914', created=1694122472, object='model', owned_by='system'), Model(id='tts-1', created=1681940951, object='model', owned_by='openai-internal'), Model(id='davinci-002', created=1692634301, object='model', owned_by='system'), Model(id='babbage-002', created=1692634615, object='model', owned_by='system'), Model(id='tts-1-1106', created=1699053241, object='model', owned_by='system'), Model(id='text-embedding-ada-002', created=1671217299, object='model', owned_by='openai-internal'), Model(id='text-embedding-3-small', created=1705948997, object='model', owned_by='system')], object='list')\n"
     ]
    }
   ],
   "source": [
    "print(models)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b69d74e-a79d-4832-9bda-2a5b9df7e68d",
   "metadata": {},
   "source": [
    "#### 查看 OpenAI 最新提供的模型 API 信息\n",
    "\n",
    "`models.data`: 目前 OpenAI 提供的大语言模型列表，列表中的每一项都对应着一个模型实例。\n",
    "\n",
    "以`GPT-3.5-Turbo`模型为例，解释说明各项参数：\n",
    "\n",
    "1. `created`: 这是模型创建的时间戳，单位为 Unix 时间戳（自 1970 年 1 月 1 日（00:00:00 GMT）以后的秒数）。\n",
    "2. `id`: 这是模型的唯一标识符。在这个例子中，模型的 ID 是 \"text-davinci-003\"。\n",
    "3. `object`: 这个字段表示的是当前对象的类型，在这个例子中，对象是 \"model\"，说明这个 JSON 对象是一个模型。\n",
    "4. `owned_by`: 这个字段表示的是模型的所有者，在这个例子中，模型的所有者是 \"openai-internal\"。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82922dd9-f38e-4ec1-8be0-361aefb99d7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Model(id='gpt-3.5-turbo', created=1626777600, object='model', owned_by='OpenAI', permission=[{'id': 'modelperm-LwHkVFn8AcMItP432fKKDIKJ', 'object': 'model_permission', 'created': 1626777600, 'allow_create_engine': True, 'allow_sampling': True, 'allow_logprobs': True, 'allow_search_indices': False, 'allow_view': True, 'allow_fine_tuning': False, 'organization': '*', 'group': None, 'is_blocking': False}], root='gpt-3.5-turbo', parent=None),\n",
       " Model(id='gpt-3.5-turbo-0613', created=1626777600, object='model', owned_by='OpenAI', permission=[{'id': 'modelperm-LwHkVFn8AcMItP432fKKDIKJ', 'object': 'model_permission', 'created': 1626777600, 'allow_create_engine': True, 'allow_sampling': True, 'allow_logprobs': True, 'allow_search_indices': False, 'allow_view': True, 'allow_fine_tuning': False, 'organization': '*', 'group': None, 'is_blocking': False}], root='gpt-3.5-turbo-0613', parent=None),\n",
       " Model(id='gpt-3.5-turbo-1106', created=1626777600, object='model', owned_by='OpenAI', permission=[{'id': 'modelperm-LwHkVFn8AcMItP432fKKDIKJ', 'object': 'model_permission', 'created': 1626777600, 'allow_create_engine': True, 'allow_sampling': True, 'allow_logprobs': True, 'allow_search_indices': False, 'allow_view': True, 'allow_fine_tuning': False, 'organization': '*', 'group': None, 'is_blocking': False}], root='gpt-3.5-turbo-1106', parent=None),\n",
       " Model(id='gpt-3.5-turbo-0125', created=1626777600, object='model', owned_by='OpenAI', permission=[{'id': 'modelperm-LwHkVFn8AcMItP432fKKDIKJ', 'object': 'model_permission', 'created': 1626777600, 'allow_create_engine': True, 'allow_sampling': True, 'allow_logprobs': True, 'allow_search_indices': False, 'allow_view': True, 'allow_fine_tuning': False, 'organization': '*', 'group': None, 'is_blocking': False}], root='gpt-3.5-turbo-0125', parent=None),\n",
       " Model(id='gpt-3.5-turbo-16k', created=1626777600, object='model', owned_by='OpenAI', permission=[{'id': 'modelperm-LwHkVFn8AcMItP432fKKDIKJ', 'object': 'model_permission', 'created': 1626777600, 'allow_create_engine': True, 'allow_sampling': True, 'allow_logprobs': True, 'allow_search_indices': False, 'allow_view': True, 'allow_fine_tuning': False, 'organization': '*', 'group': None, 'is_blocking': False}], root='gpt-3.5-turbo-16k', parent=None),\n",
       " Model(id='gpt-3.5-turbo-instruct', created=1626777600, object='model', owned_by='OpenAI', permission=[{'id': 'modelperm-LwHkVFn8AcMItP432fKKDIKJ', 'object': 'model_permission', 'created': 1626777600, 'allow_create_engine': True, 'allow_sampling': True, 'allow_logprobs': True, 'allow_search_indices': False, 'allow_view': True, 'allow_fine_tuning': False, 'organization': '*', 'group': None, 'is_blocking': False}], root='gpt-3.5-turbo-instruct', parent=None),\n",
       " Model(id='gpt-4', created=1626777600, object='model', owned_by='OpenAI', permission=[{'id': 'modelperm-LwHkVFn8AcMItP432fKKDIKJ', 'object': 'model_permission', 'created': 1626777600, 'allow_create_engine': True, 'allow_sampling': True, 'allow_logprobs': True, 'allow_search_indices': False, 'allow_view': True, 'allow_fine_tuning': False, 'organization': '*', 'group': None, 'is_blocking': False}], root='gpt-4', parent=None),\n",
       " Model(id='gpt-4-0613', created=1626777600, object='model', owned_by='OpenAI', permission=[{'id': 'modelperm-LwHkVFn8AcMItP432fKKDIKJ', 'object': 'model_permission', 'created': 1626777600, 'allow_create_engine': True, 'allow_sampling': True, 'allow_logprobs': True, 'allow_search_indices': False, 'allow_view': True, 'allow_fine_tuning': False, 'organization': '*', 'group': None, 'is_blocking': False}], root='gpt-4-0613', parent=None),\n",
       " Model(id='gpt-4-1106-preview', created=1626777600, object='model', owned_by='OpenAI', permission=[{'id': 'modelperm-LwHkVFn8AcMItP432fKKDIKJ', 'object': 'model_permission', 'created': 1626777600, 'allow_create_engine': True, 'allow_sampling': True, 'allow_logprobs': True, 'allow_search_indices': False, 'allow_view': True, 'allow_fine_tuning': False, 'organization': '*', 'group': None, 'is_blocking': False}], root='gpt-4-1106-preview', parent=None),\n",
       " Model(id='gpt-4-0125-preview', created=1626777600, object='model', owned_by='OpenAI', permission=[{'id': 'modelperm-LwHkVFn8AcMItP432fKKDIKJ', 'object': 'model_permission', 'created': 1626777600, 'allow_create_engine': True, 'allow_sampling': True, 'allow_logprobs': True, 'allow_search_indices': False, 'allow_view': True, 'allow_fine_tuning': False, 'organization': '*', 'group': None, 'is_blocking': False}], root='gpt-4-0125-preview', parent=None),\n",
       " Model(id='gpt-4-32k', created=1626777600, object='model', owned_by='OpenAI', permission=[{'id': 'modelperm-LwHkVFn8AcMItP432fKKDIKJ', 'object': 'model_permission', 'created': 1626777600, 'allow_create_engine': True, 'allow_sampling': True, 'allow_logprobs': True, 'allow_search_indices': False, 'allow_view': True, 'allow_fine_tuning': False, 'organization': '*', 'group': None, 'is_blocking': False}], root='gpt-4-32k', parent=None),\n",
       " Model(id='gpt-4-turbo-preview', created=1626777600, object='model', owned_by='OpenAI', permission=[{'id': 'modelperm-LwHkVFn8AcMItP432fKKDIKJ', 'object': 'model_permission', 'created': 1626777600, 'allow_create_engine': True, 'allow_sampling': True, 'allow_logprobs': True, 'allow_search_indices': False, 'allow_view': True, 'allow_fine_tuning': False, 'organization': '*', 'group': None, 'is_blocking': False}], root='gpt-4-turbo-preview', parent=None),\n",
       " Model(id='gpt-4-turbo', created=1626777600, object='model', owned_by='OpenAI', permission=[{'id': 'modelperm-LwHkVFn8AcMItP432fKKDIKJ', 'object': 'model_permission', 'created': 1626777600, 'allow_create_engine': True, 'allow_sampling': True, 'allow_logprobs': True, 'allow_search_indices': False, 'allow_view': True, 'allow_fine_tuning': False, 'organization': '*', 'group': None, 'is_blocking': False}], root='gpt-4-turbo', parent=None),\n",
       " Model(id='gpt-4-turbo-2024-04-09', created=1626777600, object='model', owned_by='OpenAI', permission=[{'id': 'modelperm-LwHkVFn8AcMItP432fKKDIKJ', 'object': 'model_permission', 'created': 1626777600, 'allow_create_engine': True, 'allow_sampling': True, 'allow_logprobs': True, 'allow_search_indices': False, 'allow_view': True, 'allow_fine_tuning': False, 'organization': '*', 'group': None, 'is_blocking': False}], root='gpt-4-turbo-2024-04-09', parent=None),\n",
       " Model(id='gpt-4o', created=1626777600, object='model', owned_by='OpenAI', permission=[{'id': 'modelperm-LwHkVFn8AcMItP432fKKDIKJ', 'object': 'model_permission', 'created': 1626777600, 'allow_create_engine': True, 'allow_sampling': True, 'allow_logprobs': True, 'allow_search_indices': False, 'allow_view': True, 'allow_fine_tuning': False, 'organization': '*', 'group': None, 'is_blocking': False}], root='gpt-4o', parent=None),\n",
       " Model(id='gpt-4o-2024-05-13', created=1626777600, object='model', owned_by='OpenAI', permission=[{'id': 'modelperm-LwHkVFn8AcMItP432fKKDIKJ', 'object': 'model_permission', 'created': 1626777600, 'allow_create_engine': True, 'allow_sampling': True, 'allow_logprobs': True, 'allow_search_indices': False, 'allow_view': True, 'allow_fine_tuning': False, 'organization': '*', 'group': None, 'is_blocking': False}], root='gpt-4o-2024-05-13', parent=None),\n",
       " Model(id='gpt-4o-2024-08-06', created=1626777600, object='model', owned_by='OpenAI', permission=[{'id': 'modelperm-LwHkVFn8AcMItP432fKKDIKJ', 'object': 'model_permission', 'created': 1626777600, 'allow_create_engine': True, 'allow_sampling': True, 'allow_logprobs': True, 'allow_search_indices': False, 'allow_view': True, 'allow_fine_tuning': False, 'organization': '*', 'group': None, 'is_blocking': False}], root='gpt-4o-2024-08-06', parent=None),\n",
       " Model(id='gpt-4o-2024-11-20', created=1626777600, object='model', owned_by='OpenAI', permission=[{'id': 'modelperm-LwHkVFn8AcMItP432fKKDIKJ', 'object': 'model_permission', 'created': 1626777600, 'allow_create_engine': True, 'allow_sampling': True, 'allow_logprobs': True, 'allow_search_indices': False, 'allow_view': True, 'allow_fine_tuning': False, 'organization': '*', 'group': None, 'is_blocking': False}], root='gpt-4o-2024-11-20', parent=None),\n",
       " Model(id='chatgpt-4o-latest', created=1626777600, object='model', owned_by='OpenAI', permission=[{'id': 'modelperm-LwHkVFn8AcMItP432fKKDIKJ', 'object': 'model_permission', 'created': 1626777600, 'allow_create_engine': True, 'allow_sampling': True, 'allow_logprobs': True, 'allow_search_indices': False, 'allow_view': True, 'allow_fine_tuning': False, 'organization': '*', 'group': None, 'is_blocking': False}], root='chatgpt-4o-latest', parent=None),\n",
       " Model(id='gpt-4o-mini', created=1626777600, object='model', owned_by='OpenAI', permission=[{'id': 'modelperm-LwHkVFn8AcMItP432fKKDIKJ', 'object': 'model_permission', 'created': 1626777600, 'allow_create_engine': True, 'allow_sampling': True, 'allow_logprobs': True, 'allow_search_indices': False, 'allow_view': True, 'allow_fine_tuning': False, 'organization': '*', 'group': None, 'is_blocking': False}], root='gpt-4o-mini', parent=None),\n",
       " Model(id='gpt-4o-mini-2024-07-18', created=1626777600, object='model', owned_by='OpenAI', permission=[{'id': 'modelperm-LwHkVFn8AcMItP432fKKDIKJ', 'object': 'model_permission', 'created': 1626777600, 'allow_create_engine': True, 'allow_sampling': True, 'allow_logprobs': True, 'allow_search_indices': False, 'allow_view': True, 'allow_fine_tuning': False, 'organization': '*', 'group': None, 'is_blocking': False}], root='gpt-4o-mini-2024-07-18', parent=None),\n",
       " Model(id='gpt-4-vision-preview', created=1626777600, object='model', owned_by='OpenAI', permission=[{'id': 'modelperm-LwHkVFn8AcMItP432fKKDIKJ', 'object': 'model_permission', 'created': 1626777600, 'allow_create_engine': True, 'allow_sampling': True, 'allow_logprobs': True, 'allow_search_indices': False, 'allow_view': True, 'allow_fine_tuning': False, 'organization': '*', 'group': None, 'is_blocking': False}], root='gpt-4-vision-preview', parent=None),\n",
       " Model(id='text-embedding-ada-002', created=1626777600, object='model', owned_by='OpenAI', permission=[{'id': 'modelperm-LwHkVFn8AcMItP432fKKDIKJ', 'object': 'model_permission', 'created': 1626777600, 'allow_create_engine': True, 'allow_sampling': True, 'allow_logprobs': True, 'allow_search_indices': False, 'allow_view': True, 'allow_fine_tuning': False, 'organization': '*', 'group': None, 'is_blocking': False}], root='text-embedding-ada-002', parent=None),\n",
       " Model(id='text-embedding-3-small', created=1626777600, object='model', owned_by='OpenAI', permission=[{'id': 'modelperm-LwHkVFn8AcMItP432fKKDIKJ', 'object': 'model_permission', 'created': 1626777600, 'allow_create_engine': True, 'allow_sampling': True, 'allow_logprobs': True, 'allow_search_indices': False, 'allow_view': True, 'allow_fine_tuning': False, 'organization': '*', 'group': None, 'is_blocking': False}], root='text-embedding-3-small', parent=None),\n",
       " Model(id='text-embedding-3-large', created=1626777600, object='model', owned_by='OpenAI', permission=[{'id': 'modelperm-LwHkVFn8AcMItP432fKKDIKJ', 'object': 'model_permission', 'created': 1626777600, 'allow_create_engine': True, 'allow_sampling': True, 'allow_logprobs': True, 'allow_search_indices': False, 'allow_view': True, 'allow_fine_tuning': False, 'organization': '*', 'group': None, 'is_blocking': False}], root='text-embedding-3-large', parent=None),\n",
       " Model(id='text-curie-001', created=1626777600, object='model', owned_by='OpenAI', permission=[{'id': 'modelperm-LwHkVFn8AcMItP432fKKDIKJ', 'object': 'model_permission', 'created': 1626777600, 'allow_create_engine': True, 'allow_sampling': True, 'allow_logprobs': True, 'allow_search_indices': False, 'allow_view': True, 'allow_fine_tuning': False, 'organization': '*', 'group': None, 'is_blocking': False}], root='text-curie-001', parent=None),\n",
       " Model(id='text-babbage-001', created=1626777600, object='model', owned_by='OpenAI', permission=[{'id': 'modelperm-LwHkVFn8AcMItP432fKKDIKJ', 'object': 'model_permission', 'created': 1626777600, 'allow_create_engine': True, 'allow_sampling': True, 'allow_logprobs': True, 'allow_search_indices': False, 'allow_view': True, 'allow_fine_tuning': False, 'organization': '*', 'group': None, 'is_blocking': False}], root='text-babbage-001', parent=None),\n",
       " Model(id='text-ada-001', created=1626777600, object='model', owned_by='OpenAI', permission=[{'id': 'modelperm-LwHkVFn8AcMItP432fKKDIKJ', 'object': 'model_permission', 'created': 1626777600, 'allow_create_engine': True, 'allow_sampling': True, 'allow_logprobs': True, 'allow_search_indices': False, 'allow_view': True, 'allow_fine_tuning': False, 'organization': '*', 'group': None, 'is_blocking': False}], root='text-ada-001', parent=None),\n",
       " Model(id='text-davinci-002', created=1626777600, object='model', owned_by='OpenAI', permission=[{'id': 'modelperm-LwHkVFn8AcMItP432fKKDIKJ', 'object': 'model_permission', 'created': 1626777600, 'allow_create_engine': True, 'allow_sampling': True, 'allow_logprobs': True, 'allow_search_indices': False, 'allow_view': True, 'allow_fine_tuning': False, 'organization': '*', 'group': None, 'is_blocking': False}], root='text-davinci-002', parent=None),\n",
       " Model(id='text-davinci-003', created=1626777600, object='model', owned_by='OpenAI', permission=[{'id': 'modelperm-LwHkVFn8AcMItP432fKKDIKJ', 'object': 'model_permission', 'created': 1626777600, 'allow_create_engine': True, 'allow_sampling': True, 'allow_logprobs': True, 'allow_search_indices': False, 'allow_view': True, 'allow_fine_tuning': False, 'organization': '*', 'group': None, 'is_blocking': False}], root='text-davinci-003', parent=None),\n",
       " Model(id='text-moderation-latest', created=1626777600, object='model', owned_by='OpenAI', permission=[{'id': 'modelperm-LwHkVFn8AcMItP432fKKDIKJ', 'object': 'model_permission', 'created': 1626777600, 'allow_create_engine': True, 'allow_sampling': True, 'allow_logprobs': True, 'allow_search_indices': False, 'allow_view': True, 'allow_fine_tuning': False, 'organization': '*', 'group': None, 'is_blocking': False}], root='text-moderation-latest', parent=None),\n",
       " Model(id='text-moderation-stable', created=1626777600, object='model', owned_by='OpenAI', permission=[{'id': 'modelperm-LwHkVFn8AcMItP432fKKDIKJ', 'object': 'model_permission', 'created': 1626777600, 'allow_create_engine': True, 'allow_sampling': True, 'allow_logprobs': True, 'allow_search_indices': False, 'allow_view': True, 'allow_fine_tuning': False, 'organization': '*', 'group': None, 'is_blocking': False}], root='text-moderation-stable', parent=None),\n",
       " Model(id='text-davinci-edit-001', created=1626777600, object='model', owned_by='OpenAI', permission=[{'id': 'modelperm-LwHkVFn8AcMItP432fKKDIKJ', 'object': 'model_permission', 'created': 1626777600, 'allow_create_engine': True, 'allow_sampling': True, 'allow_logprobs': True, 'allow_search_indices': False, 'allow_view': True, 'allow_fine_tuning': False, 'organization': '*', 'group': None, 'is_blocking': False}], root='text-davinci-edit-001', parent=None),\n",
       " Model(id='davinci-002', created=1626777600, object='model', owned_by='OpenAI', permission=[{'id': 'modelperm-LwHkVFn8AcMItP432fKKDIKJ', 'object': 'model_permission', 'created': 1626777600, 'allow_create_engine': True, 'allow_sampling': True, 'allow_logprobs': True, 'allow_search_indices': False, 'allow_view': True, 'allow_fine_tuning': False, 'organization': '*', 'group': None, 'is_blocking': False}], root='davinci-002', parent=None),\n",
       " Model(id='babbage-002', created=1626777600, object='model', owned_by='OpenAI', permission=[{'id': 'modelperm-LwHkVFn8AcMItP432fKKDIKJ', 'object': 'model_permission', 'created': 1626777600, 'allow_create_engine': True, 'allow_sampling': True, 'allow_logprobs': True, 'allow_search_indices': False, 'allow_view': True, 'allow_fine_tuning': False, 'organization': '*', 'group': None, 'is_blocking': False}], root='babbage-002', parent=None),\n",
       " Model(id='dall-e-2', created=1626777600, object='model', owned_by='OpenAI', permission=[{'id': 'modelperm-LwHkVFn8AcMItP432fKKDIKJ', 'object': 'model_permission', 'created': 1626777600, 'allow_create_engine': True, 'allow_sampling': True, 'allow_logprobs': True, 'allow_search_indices': False, 'allow_view': True, 'allow_fine_tuning': False, 'organization': '*', 'group': None, 'is_blocking': False}], root='dall-e-2', parent=None),\n",
       " Model(id='dall-e-3', created=1626777600, object='model', owned_by='OpenAI', permission=[{'id': 'modelperm-LwHkVFn8AcMItP432fKKDIKJ', 'object': 'model_permission', 'created': 1626777600, 'allow_create_engine': True, 'allow_sampling': True, 'allow_logprobs': True, 'allow_search_indices': False, 'allow_view': True, 'allow_fine_tuning': False, 'organization': '*', 'group': None, 'is_blocking': False}], root='dall-e-3', parent=None),\n",
       " Model(id='whisper-1', created=1626777600, object='model', owned_by='OpenAI', permission=[{'id': 'modelperm-LwHkVFn8AcMItP432fKKDIKJ', 'object': 'model_permission', 'created': 1626777600, 'allow_create_engine': True, 'allow_sampling': True, 'allow_logprobs': True, 'allow_search_indices': False, 'allow_view': True, 'allow_fine_tuning': False, 'organization': '*', 'group': None, 'is_blocking': False}], root='whisper-1', parent=None),\n",
       " Model(id='tts-1', created=1626777600, object='model', owned_by='OpenAI', permission=[{'id': 'modelperm-LwHkVFn8AcMItP432fKKDIKJ', 'object': 'model_permission', 'created': 1626777600, 'allow_create_engine': True, 'allow_sampling': True, 'allow_logprobs': True, 'allow_search_indices': False, 'allow_view': True, 'allow_fine_tuning': False, 'organization': '*', 'group': None, 'is_blocking': False}], root='tts-1', parent=None),\n",
       " Model(id='tts-1-hd', created=1626777600, object='model', owned_by='OpenAI', permission=[{'id': 'modelperm-LwHkVFn8AcMItP432fKKDIKJ', 'object': 'model_permission', 'created': 1626777600, 'allow_create_engine': True, 'allow_sampling': True, 'allow_logprobs': True, 'allow_search_indices': False, 'allow_view': True, 'allow_fine_tuning': False, 'organization': '*', 'group': None, 'is_blocking': False}], root='tts-1-hd', parent=None),\n",
       " Model(id='o1', created=1626777600, object='model', owned_by='OpenAI', permission=[{'id': 'modelperm-LwHkVFn8AcMItP432fKKDIKJ', 'object': 'model_permission', 'created': 1626777600, 'allow_create_engine': True, 'allow_sampling': True, 'allow_logprobs': True, 'allow_search_indices': False, 'allow_view': True, 'allow_fine_tuning': False, 'organization': '*', 'group': None, 'is_blocking': False}], root='o1', parent=None),\n",
       " Model(id='o1-2024-12-17', created=1626777600, object='model', owned_by='OpenAI', permission=[{'id': 'modelperm-LwHkVFn8AcMItP432fKKDIKJ', 'object': 'model_permission', 'created': 1626777600, 'allow_create_engine': True, 'allow_sampling': True, 'allow_logprobs': True, 'allow_search_indices': False, 'allow_view': True, 'allow_fine_tuning': False, 'organization': '*', 'group': None, 'is_blocking': False}], root='o1-2024-12-17', parent=None),\n",
       " Model(id='o1-preview', created=1626777600, object='model', owned_by='OpenAI', permission=[{'id': 'modelperm-LwHkVFn8AcMItP432fKKDIKJ', 'object': 'model_permission', 'created': 1626777600, 'allow_create_engine': True, 'allow_sampling': True, 'allow_logprobs': True, 'allow_search_indices': False, 'allow_view': True, 'allow_fine_tuning': False, 'organization': '*', 'group': None, 'is_blocking': False}], root='o1-preview', parent=None),\n",
       " Model(id='o1-preview-2024-09-12', created=1626777600, object='model', owned_by='OpenAI', permission=[{'id': 'modelperm-LwHkVFn8AcMItP432fKKDIKJ', 'object': 'model_permission', 'created': 1626777600, 'allow_create_engine': True, 'allow_sampling': True, 'allow_logprobs': True, 'allow_search_indices': False, 'allow_view': True, 'allow_fine_tuning': False, 'organization': '*', 'group': None, 'is_blocking': False}], root='o1-preview-2024-09-12', parent=None),\n",
       " Model(id='o1-mini', created=1626777600, object='model', owned_by='OpenAI', permission=[{'id': 'modelperm-LwHkVFn8AcMItP432fKKDIKJ', 'object': 'model_permission', 'created': 1626777600, 'allow_create_engine': True, 'allow_sampling': True, 'allow_logprobs': True, 'allow_search_indices': False, 'allow_view': True, 'allow_fine_tuning': False, 'organization': '*', 'group': None, 'is_blocking': False}], root='o1-mini', parent=None),\n",
       " Model(id='o1-mini-2024-09-12', created=1626777600, object='model', owned_by='OpenAI', permission=[{'id': 'modelperm-LwHkVFn8AcMItP432fKKDIKJ', 'object': 'model_permission', 'created': 1626777600, 'allow_create_engine': True, 'allow_sampling': True, 'allow_logprobs': True, 'allow_search_indices': False, 'allow_view': True, 'allow_fine_tuning': False, 'organization': '*', 'group': None, 'is_blocking': False}], root='o1-mini-2024-09-12', parent=None),\n",
       " Model(id='claude-3-haiku-20240307', created=1626777600, object='model', owned_by='Anthropic', permission=[{'id': 'modelperm-LwHkVFn8AcMItP432fKKDIKJ', 'object': 'model_permission', 'created': 1626777600, 'allow_create_engine': True, 'allow_sampling': True, 'allow_logprobs': True, 'allow_search_indices': False, 'allow_view': True, 'allow_fine_tuning': False, 'organization': '*', 'group': None, 'is_blocking': False}], root='claude-3-haiku-20240307', parent=None),\n",
       " Model(id='claude-3-5-haiku-20241022', created=1626777600, object='model', owned_by='Anthropic', permission=[{'id': 'modelperm-LwHkVFn8AcMItP432fKKDIKJ', 'object': 'model_permission', 'created': 1626777600, 'allow_create_engine': True, 'allow_sampling': True, 'allow_logprobs': True, 'allow_search_indices': False, 'allow_view': True, 'allow_fine_tuning': False, 'organization': '*', 'group': None, 'is_blocking': False}], root='claude-3-5-haiku-20241022', parent=None),\n",
       " Model(id='claude-3-sonnet-20240229', created=1626777600, object='model', owned_by='Anthropic', permission=[{'id': 'modelperm-LwHkVFn8AcMItP432fKKDIKJ', 'object': 'model_permission', 'created': 1626777600, 'allow_create_engine': True, 'allow_sampling': True, 'allow_logprobs': True, 'allow_search_indices': False, 'allow_view': True, 'allow_fine_tuning': False, 'organization': '*', 'group': None, 'is_blocking': False}], root='claude-3-sonnet-20240229', parent=None),\n",
       " Model(id='claude-3-opus-20240229', created=1626777600, object='model', owned_by='Anthropic', permission=[{'id': 'modelperm-LwHkVFn8AcMItP432fKKDIKJ', 'object': 'model_permission', 'created': 1626777600, 'allow_create_engine': True, 'allow_sampling': True, 'allow_logprobs': True, 'allow_search_indices': False, 'allow_view': True, 'allow_fine_tuning': False, 'organization': '*', 'group': None, 'is_blocking': False}], root='claude-3-opus-20240229', parent=None),\n",
       " Model(id='claude-3-5-sonnet-20240620', created=1626777600, object='model', owned_by='Anthropic', permission=[{'id': 'modelperm-LwHkVFn8AcMItP432fKKDIKJ', 'object': 'model_permission', 'created': 1626777600, 'allow_create_engine': True, 'allow_sampling': True, 'allow_logprobs': True, 'allow_search_indices': False, 'allow_view': True, 'allow_fine_tuning': False, 'organization': '*', 'group': None, 'is_blocking': False}], root='claude-3-5-sonnet-20240620', parent=None),\n",
       " Model(id='claude-3-5-sonnet-20241022', created=1626777600, object='model', owned_by='Anthropic', permission=[{'id': 'modelperm-LwHkVFn8AcMItP432fKKDIKJ', 'object': 'model_permission', 'created': 1626777600, 'allow_create_engine': True, 'allow_sampling': True, 'allow_logprobs': True, 'allow_search_indices': False, 'allow_view': True, 'allow_fine_tuning': False, 'organization': '*', 'group': None, 'is_blocking': False}], root='claude-3-5-sonnet-20241022', parent=None),\n",
       " Model(id='claude-3-5-sonnet-latest', created=1626777600, object='model', owned_by='Anthropic', permission=[{'id': 'modelperm-LwHkVFn8AcMItP432fKKDIKJ', 'object': 'model_permission', 'created': 1626777600, 'allow_create_engine': True, 'allow_sampling': True, 'allow_logprobs': True, 'allow_search_indices': False, 'allow_view': True, 'allow_fine_tuning': False, 'organization': '*', 'group': None, 'is_blocking': False}], root='claude-3-5-sonnet-latest', parent=None),\n",
       " Model(id='glm-4', created=1626777600, object='model', owned_by='智谱 ChatGLM', permission=[{'id': 'modelperm-LwHkVFn8AcMItP432fKKDIKJ', 'object': 'model_permission', 'created': 1626777600, 'allow_create_engine': True, 'allow_sampling': True, 'allow_logprobs': True, 'allow_search_indices': False, 'allow_view': True, 'allow_fine_tuning': False, 'organization': '*', 'group': None, 'is_blocking': False}], root='glm-4', parent=None),\n",
       " Model(id='glm-3-turbo', created=1626777600, object='model', owned_by='智谱 ChatGLM', permission=[{'id': 'modelperm-LwHkVFn8AcMItP432fKKDIKJ', 'object': 'model_permission', 'created': 1626777600, 'allow_create_engine': True, 'allow_sampling': True, 'allow_logprobs': True, 'allow_search_indices': False, 'allow_view': True, 'allow_fine_tuning': False, 'organization': '*', 'group': None, 'is_blocking': False}], root='glm-3-turbo', parent=None),\n",
       " Model(id='qwen-turbo', created=1626777600, object='model', owned_by='Qwen', permission=[{'id': 'modelperm-LwHkVFn8AcMItP432fKKDIKJ', 'object': 'model_permission', 'created': 1626777600, 'allow_create_engine': True, 'allow_sampling': True, 'allow_logprobs': True, 'allow_search_indices': False, 'allow_view': True, 'allow_fine_tuning': False, 'organization': '*', 'group': None, 'is_blocking': False}], root='qwen-turbo', parent=None),\n",
       " Model(id='qwen-plus', created=1626777600, object='model', owned_by='Qwen', permission=[{'id': 'modelperm-LwHkVFn8AcMItP432fKKDIKJ', 'object': 'model_permission', 'created': 1626777600, 'allow_create_engine': True, 'allow_sampling': True, 'allow_logprobs': True, 'allow_search_indices': False, 'allow_view': True, 'allow_fine_tuning': False, 'organization': '*', 'group': None, 'is_blocking': False}], root='qwen-plus', parent=None),\n",
       " Model(id='qwen-max', created=1626777600, object='model', owned_by='Qwen', permission=[{'id': 'modelperm-LwHkVFn8AcMItP432fKKDIKJ', 'object': 'model_permission', 'created': 1626777600, 'allow_create_engine': True, 'allow_sampling': True, 'allow_logprobs': True, 'allow_search_indices': False, 'allow_view': True, 'allow_fine_tuning': False, 'organization': '*', 'group': None, 'is_blocking': False}], root='qwen-max', parent=None),\n",
       " Model(id='qwen-max-longcontext', created=1626777600, object='model', owned_by='Qwen', permission=[{'id': 'modelperm-LwHkVFn8AcMItP432fKKDIKJ', 'object': 'model_permission', 'created': 1626777600, 'allow_create_engine': True, 'allow_sampling': True, 'allow_logprobs': True, 'allow_search_indices': False, 'allow_view': True, 'allow_fine_tuning': False, 'organization': '*', 'group': None, 'is_blocking': False}], root='qwen-max-longcontext', parent=None),\n",
       " Model(id='qwen2.5-72b-instruct', created=1626777600, object='model', owned_by='Qwen', permission=[{'id': 'modelperm-LwHkVFn8AcMItP432fKKDIKJ', 'object': 'model_permission', 'created': 1626777600, 'allow_create_engine': True, 'allow_sampling': True, 'allow_logprobs': True, 'allow_search_indices': False, 'allow_view': True, 'allow_fine_tuning': False, 'organization': '*', 'group': None, 'is_blocking': False}], root='qwen2.5-72b-instruct', parent=None),\n",
       " Model(id='qwen2.5-32b-instruct', created=1626777600, object='model', owned_by='Qwen', permission=[{'id': 'modelperm-LwHkVFn8AcMItP432fKKDIKJ', 'object': 'model_permission', 'created': 1626777600, 'allow_create_engine': True, 'allow_sampling': True, 'allow_logprobs': True, 'allow_search_indices': False, 'allow_view': True, 'allow_fine_tuning': False, 'organization': '*', 'group': None, 'is_blocking': False}], root='qwen2.5-32b-instruct', parent=None),\n",
       " Model(id='qwen2.5-14b-instruct', created=1626777600, object='model', owned_by='Qwen', permission=[{'id': 'modelperm-LwHkVFn8AcMItP432fKKDIKJ', 'object': 'model_permission', 'created': 1626777600, 'allow_create_engine': True, 'allow_sampling': True, 'allow_logprobs': True, 'allow_search_indices': False, 'allow_view': True, 'allow_fine_tuning': False, 'organization': '*', 'group': None, 'is_blocking': False}], root='qwen2.5-14b-instruct', parent=None),\n",
       " Model(id='qwen2.5-7b-instruct', created=1626777600, object='model', owned_by='Qwen', permission=[{'id': 'modelperm-LwHkVFn8AcMItP432fKKDIKJ', 'object': 'model_permission', 'created': 1626777600, 'allow_create_engine': True, 'allow_sampling': True, 'allow_logprobs': True, 'allow_search_indices': False, 'allow_view': True, 'allow_fine_tuning': False, 'organization': '*', 'group': None, 'is_blocking': False}], root='qwen2.5-7b-instruct', parent=None),\n",
       " Model(id='qwen2.5-3b-instruct', created=1626777600, object='model', owned_by='Qwen', permission=[{'id': 'modelperm-LwHkVFn8AcMItP432fKKDIKJ', 'object': 'model_permission', 'created': 1626777600, 'allow_create_engine': True, 'allow_sampling': True, 'allow_logprobs': True, 'allow_search_indices': False, 'allow_view': True, 'allow_fine_tuning': False, 'organization': '*', 'group': None, 'is_blocking': False}], root='qwen2.5-3b-instruct', parent=None),\n",
       " Model(id='qwen2.5-math-72b-instruct', created=1626777600, object='model', owned_by='Qwen', permission=[{'id': 'modelperm-LwHkVFn8AcMItP432fKKDIKJ', 'object': 'model_permission', 'created': 1626777600, 'allow_create_engine': True, 'allow_sampling': True, 'allow_logprobs': True, 'allow_search_indices': False, 'allow_view': True, 'allow_fine_tuning': False, 'organization': '*', 'group': None, 'is_blocking': False}], root='qwen2.5-math-72b-instruct', parent=None),\n",
       " Model(id='qwen2.5-math-7b-instruct', created=1626777600, object='model', owned_by='Qwen', permission=[{'id': 'modelperm-LwHkVFn8AcMItP432fKKDIKJ', 'object': 'model_permission', 'created': 1626777600, 'allow_create_engine': True, 'allow_sampling': True, 'allow_logprobs': True, 'allow_search_indices': False, 'allow_view': True, 'allow_fine_tuning': False, 'organization': '*', 'group': None, 'is_blocking': False}], root='qwen2.5-math-7b-instruct', parent=None),\n",
       " Model(id='qwen2.5-coder-7b-instruct', created=1626777600, object='model', owned_by='Qwen', permission=[{'id': 'modelperm-LwHkVFn8AcMItP432fKKDIKJ', 'object': 'model_permission', 'created': 1626777600, 'allow_create_engine': True, 'allow_sampling': True, 'allow_logprobs': True, 'allow_search_indices': False, 'allow_view': True, 'allow_fine_tuning': False, 'organization': '*', 'group': None, 'is_blocking': False}], root='qwen2.5-coder-7b-instruct', parent=None),\n",
       " Model(id='qwen2.5-coder-1.5b-instruct', created=1626777600, object='model', owned_by='Qwen', permission=[{'id': 'modelperm-LwHkVFn8AcMItP432fKKDIKJ', 'object': 'model_permission', 'created': 1626777600, 'allow_create_engine': True, 'allow_sampling': True, 'allow_logprobs': True, 'allow_search_indices': False, 'allow_view': True, 'allow_fine_tuning': False, 'organization': '*', 'group': None, 'is_blocking': False}], root='qwen2.5-coder-1.5b-instruct', parent=None),\n",
       " Model(id='gemini-pro', created=1626777600, object='model', owned_by='Google', permission=[{'id': 'modelperm-LwHkVFn8AcMItP432fKKDIKJ', 'object': 'model_permission', 'created': 1626777600, 'allow_create_engine': True, 'allow_sampling': True, 'allow_logprobs': True, 'allow_search_indices': False, 'allow_view': True, 'allow_fine_tuning': False, 'organization': '*', 'group': None, 'is_blocking': False}], root='gemini-pro', parent=None),\n",
       " Model(id='gemini-1.5-flash', created=1626777600, object='model', owned_by='Google', permission=[{'id': 'modelperm-LwHkVFn8AcMItP432fKKDIKJ', 'object': 'model_permission', 'created': 1626777600, 'allow_create_engine': True, 'allow_sampling': True, 'allow_logprobs': True, 'allow_search_indices': False, 'allow_view': True, 'allow_fine_tuning': False, 'organization': '*', 'group': None, 'is_blocking': False}], root='gemini-1.5-flash', parent=None),\n",
       " Model(id='gemini-1.5-pro', created=1626777600, object='model', owned_by='Google', permission=[{'id': 'modelperm-LwHkVFn8AcMItP432fKKDIKJ', 'object': 'model_permission', 'created': 1626777600, 'allow_create_engine': True, 'allow_sampling': True, 'allow_logprobs': True, 'allow_search_indices': False, 'allow_view': True, 'allow_fine_tuning': False, 'organization': '*', 'group': None, 'is_blocking': False}], root='gemini-1.5-pro', parent=None),\n",
       " Model(id='gemini-2.0-flash-exp', created=1626777600, object='model', owned_by='Google', permission=[{'id': 'modelperm-LwHkVFn8AcMItP432fKKDIKJ', 'object': 'model_permission', 'created': 1626777600, 'allow_create_engine': True, 'allow_sampling': True, 'allow_logprobs': True, 'allow_search_indices': False, 'allow_view': True, 'allow_fine_tuning': False, 'organization': '*', 'group': None, 'is_blocking': False}], root='gemini-2.0-flash-exp', parent=None),\n",
       " Model(id='gemini-2.0-flash-thinking-exp', created=1626777600, object='model', owned_by='Google', permission=[{'id': 'modelperm-LwHkVFn8AcMItP432fKKDIKJ', 'object': 'model_permission', 'created': 1626777600, 'allow_create_engine': True, 'allow_sampling': True, 'allow_logprobs': True, 'allow_search_indices': False, 'allow_view': True, 'allow_fine_tuning': False, 'organization': '*', 'group': None, 'is_blocking': False}], root='gemini-2.0-flash-thinking-exp', parent=None),\n",
       " Model(id='claude-3-5-haiku-20241022', created=1626777600, object='model', owned_by='Anthropic', permission=[{'id': 'modelperm-LwHkVFn8AcMItP432fKKDIKJ', 'object': 'model_permission', 'created': 1626777600, 'allow_create_engine': True, 'allow_sampling': True, 'allow_logprobs': True, 'allow_search_indices': False, 'allow_view': True, 'allow_fine_tuning': False, 'organization': '*', 'group': None, 'is_blocking': False}], root='claude-3-5-haiku-20241022', parent=None),\n",
       " Model(id='claude-3-5-sonnet-20240620', created=1626777600, object='model', owned_by='Anthropic', permission=[{'id': 'modelperm-LwHkVFn8AcMItP432fKKDIKJ', 'object': 'model_permission', 'created': 1626777600, 'allow_create_engine': True, 'allow_sampling': True, 'allow_logprobs': True, 'allow_search_indices': False, 'allow_view': True, 'allow_fine_tuning': False, 'organization': '*', 'group': None, 'is_blocking': False}], root='claude-3-5-sonnet-20240620', parent=None),\n",
       " Model(id='claude-3-5-sonnet-20241022', created=1626777600, object='model', owned_by='Anthropic', permission=[{'id': 'modelperm-LwHkVFn8AcMItP432fKKDIKJ', 'object': 'model_permission', 'created': 1626777600, 'allow_create_engine': True, 'allow_sampling': True, 'allow_logprobs': True, 'allow_search_indices': False, 'allow_view': True, 'allow_fine_tuning': False, 'organization': '*', 'group': None, 'is_blocking': False}], root='claude-3-5-sonnet-20241022', parent=None),\n",
       " Model(id='claude-3-opus-20240229', created=1626777600, object='model', owned_by='Anthropic', permission=[{'id': 'modelperm-LwHkVFn8AcMItP432fKKDIKJ', 'object': 'model_permission', 'created': 1626777600, 'allow_create_engine': True, 'allow_sampling': True, 'allow_logprobs': True, 'allow_search_indices': False, 'allow_view': True, 'allow_fine_tuning': False, 'organization': '*', 'group': None, 'is_blocking': False}], root='claude-3-opus-20240229', parent=None),\n",
       " Model(id='claude-3-7-sonnet-20250219', created=1626777600, object='model', owned_by='Anthropic', permission=[{'id': 'modelperm-LwHkVFn8AcMItP432fKKDIKJ', 'object': 'model_permission', 'created': 1626777600, 'allow_create_engine': True, 'allow_sampling': True, 'allow_logprobs': True, 'allow_search_indices': False, 'allow_view': True, 'allow_fine_tuning': False, 'organization': '*', 'group': None, 'is_blocking': False}], root='claude-3-7-sonnet-20250219', parent=None),\n",
       " Model(id='llama3-8b-8192', created=1626777600, object='model', owned_by='Meta', permission=[{'id': 'modelperm-LwHkVFn8AcMItP432fKKDIKJ', 'object': 'model_permission', 'created': 1626777600, 'allow_create_engine': True, 'allow_sampling': True, 'allow_logprobs': True, 'allow_search_indices': False, 'allow_view': True, 'allow_fine_tuning': False, 'organization': '*', 'group': None, 'is_blocking': False}], root='llama3-8b-8192', parent=None),\n",
       " Model(id='claude-3-haiku-20240307', created=1626777600, object='model', owned_by='Anthropic', permission=[{'id': 'modelperm-LwHkVFn8AcMItP432fKKDIKJ', 'object': 'model_permission', 'created': 1626777600, 'allow_create_engine': True, 'allow_sampling': True, 'allow_logprobs': True, 'allow_search_indices': False, 'allow_view': True, 'allow_fine_tuning': False, 'organization': '*', 'group': None, 'is_blocking': False}], root='claude-3-haiku-20240307', parent=None),\n",
       " Model(id='claude-3-sonnet-20240229', created=1626777600, object='model', owned_by='Anthropic', permission=[{'id': 'modelperm-LwHkVFn8AcMItP432fKKDIKJ', 'object': 'model_permission', 'created': 1626777600, 'allow_create_engine': True, 'allow_sampling': True, 'allow_logprobs': True, 'allow_search_indices': False, 'allow_view': True, 'allow_fine_tuning': False, 'organization': '*', 'group': None, 'is_blocking': False}], root='claude-3-sonnet-20240229', parent=None),\n",
       " Model(id='claude-3-5-sonnet-latest', created=1626777600, object='model', owned_by='Anthropic', permission=[{'id': 'modelperm-LwHkVFn8AcMItP432fKKDIKJ', 'object': 'model_permission', 'created': 1626777600, 'allow_create_engine': True, 'allow_sampling': True, 'allow_logprobs': True, 'allow_search_indices': False, 'allow_view': True, 'allow_fine_tuning': False, 'organization': '*', 'group': None, 'is_blocking': False}], root='claude-3-5-sonnet-latest', parent=None),\n",
       " Model(id='llama3-70b-8192', created=1626777600, object='model', owned_by='Meta', permission=[{'id': 'modelperm-LwHkVFn8AcMItP432fKKDIKJ', 'object': 'model_permission', 'created': 1626777600, 'allow_create_engine': True, 'allow_sampling': True, 'allow_logprobs': True, 'allow_search_indices': False, 'allow_view': True, 'allow_fine_tuning': False, 'organization': '*', 'group': None, 'is_blocking': False}], root='llama3-70b-8192', parent=None),\n",
       " Model(id='command', created=1626777600, object='model', owned_by='Cohere', permission=[{'id': 'modelperm-LwHkVFn8AcMItP432fKKDIKJ', 'object': 'model_permission', 'created': 1626777600, 'allow_create_engine': True, 'allow_sampling': True, 'allow_logprobs': True, 'allow_search_indices': False, 'allow_view': True, 'allow_fine_tuning': False, 'organization': '*', 'group': None, 'is_blocking': False}], root='command', parent=None),\n",
       " Model(id='command-nightly', created=1626777600, object='model', owned_by='Cohere', permission=[{'id': 'modelperm-LwHkVFn8AcMItP432fKKDIKJ', 'object': 'model_permission', 'created': 1626777600, 'allow_create_engine': True, 'allow_sampling': True, 'allow_logprobs': True, 'allow_search_indices': False, 'allow_view': True, 'allow_fine_tuning': False, 'organization': '*', 'group': None, 'is_blocking': False}], root='command-nightly', parent=None),\n",
       " Model(id='command-light', created=1626777600, object='model', owned_by='Cohere', permission=[{'id': 'modelperm-LwHkVFn8AcMItP432fKKDIKJ', 'object': 'model_permission', 'created': 1626777600, 'allow_create_engine': True, 'allow_sampling': True, 'allow_logprobs': True, 'allow_search_indices': False, 'allow_view': True, 'allow_fine_tuning': False, 'organization': '*', 'group': None, 'is_blocking': False}], root='command-light', parent=None),\n",
       " Model(id='command-light-nightly', created=1626777600, object='model', owned_by='Cohere', permission=[{'id': 'modelperm-LwHkVFn8AcMItP432fKKDIKJ', 'object': 'model_permission', 'created': 1626777600, 'allow_create_engine': True, 'allow_sampling': True, 'allow_logprobs': True, 'allow_search_indices': False, 'allow_view': True, 'allow_fine_tuning': False, 'organization': '*', 'group': None, 'is_blocking': False}], root='command-light-nightly', parent=None),\n",
       " Model(id='command-r', created=1626777600, object='model', owned_by='Cohere', permission=[{'id': 'modelperm-LwHkVFn8AcMItP432fKKDIKJ', 'object': 'model_permission', 'created': 1626777600, 'allow_create_engine': True, 'allow_sampling': True, 'allow_logprobs': True, 'allow_search_indices': False, 'allow_view': True, 'allow_fine_tuning': False, 'organization': '*', 'group': None, 'is_blocking': False}], root='command-r', parent=None),\n",
       " Model(id='command-r-plus', created=1626777600, object='model', owned_by='Cohere', permission=[{'id': 'modelperm-LwHkVFn8AcMItP432fKKDIKJ', 'object': 'model_permission', 'created': 1626777600, 'allow_create_engine': True, 'allow_sampling': True, 'allow_logprobs': True, 'allow_search_indices': False, 'allow_view': True, 'allow_fine_tuning': False, 'organization': '*', 'group': None, 'is_blocking': False}], root='command-r-plus', parent=None),\n",
       " Model(id='claude-3-5-sonnet@20240620', created=1626777600, object='model', owned_by='Anthropic', permission=[{'id': 'modelperm-LwHkVFn8AcMItP432fKKDIKJ', 'object': 'model_permission', 'created': 1626777600, 'allow_create_engine': True, 'allow_sampling': True, 'allow_logprobs': True, 'allow_search_indices': False, 'allow_view': True, 'allow_fine_tuning': False, 'organization': '*', 'group': None, 'is_blocking': False}], root='claude-3-5-sonnet@20240620', parent=None),\n",
       " Model(id='gemini-pro', created=1626777600, object='model', owned_by='Google', permission=[{'id': 'modelperm-LwHkVFn8AcMItP432fKKDIKJ', 'object': 'model_permission', 'created': 1626777600, 'allow_create_engine': True, 'allow_sampling': True, 'allow_logprobs': True, 'allow_search_indices': False, 'allow_view': True, 'allow_fine_tuning': False, 'organization': '*', 'group': None, 'is_blocking': False}], root='gemini-pro', parent=None),\n",
       " Model(id='gemini-1.5-pro-002', created=1626777600, object='model', owned_by='Google', permission=[{'id': 'modelperm-LwHkVFn8AcMItP432fKKDIKJ', 'object': 'model_permission', 'created': 1626777600, 'allow_create_engine': True, 'allow_sampling': True, 'allow_logprobs': True, 'allow_search_indices': False, 'allow_view': True, 'allow_fine_tuning': False, 'organization': '*', 'group': None, 'is_blocking': False}], root='gemini-1.5-pro-002', parent=None),\n",
       " Model(id='gemini-1.5-flash-002', created=1626777600, object='model', owned_by='Google', permission=[{'id': 'modelperm-LwHkVFn8AcMItP432fKKDIKJ', 'object': 'model_permission', 'created': 1626777600, 'allow_create_engine': True, 'allow_sampling': True, 'allow_logprobs': True, 'allow_search_indices': False, 'allow_view': True, 'allow_fine_tuning': False, 'organization': '*', 'group': None, 'is_blocking': False}], root='gemini-1.5-flash-002', parent=None),\n",
       " Model(id='gemini-2.0-flash-exp', created=1626777600, object='model', owned_by='Google', permission=[{'id': 'modelperm-LwHkVFn8AcMItP432fKKDIKJ', 'object': 'model_permission', 'created': 1626777600, 'allow_create_engine': True, 'allow_sampling': True, 'allow_logprobs': True, 'allow_search_indices': False, 'allow_view': True, 'allow_fine_tuning': False, 'organization': '*', 'group': None, 'is_blocking': False}], root='gemini-2.0-flash-exp', parent=None),\n",
       " Model(id='gemini-2.0-flash-thinking-exp', created=1626777600, object='model', owned_by='Google', permission=[{'id': 'modelperm-LwHkVFn8AcMItP432fKKDIKJ', 'object': 'model_permission', 'created': 1626777600, 'allow_create_engine': True, 'allow_sampling': True, 'allow_logprobs': True, 'allow_search_indices': False, 'allow_view': True, 'allow_fine_tuning': False, 'organization': '*', 'group': None, 'is_blocking': False}], root='gemini-2.0-flash-thinking-exp', parent=None),\n",
       " Model(id='moonshot-v1-8k', created=1626777600, object='model', owned_by='moonshot', permission=[{'id': 'modelperm-LwHkVFn8AcMItP432fKKDIKJ', 'object': 'model_permission', 'created': 1626777600, 'allow_create_engine': True, 'allow_sampling': True, 'allow_logprobs': True, 'allow_search_indices': False, 'allow_view': True, 'allow_fine_tuning': False, 'organization': '*', 'group': None, 'is_blocking': False}], root='moonshot-v1-8k', parent=None),\n",
       " Model(id='moonshot-v1-32k', created=1626777600, object='model', owned_by='moonshot', permission=[{'id': 'modelperm-LwHkVFn8AcMItP432fKKDIKJ', 'object': 'model_permission', 'created': 1626777600, 'allow_create_engine': True, 'allow_sampling': True, 'allow_logprobs': True, 'allow_search_indices': False, 'allow_view': True, 'allow_fine_tuning': False, 'organization': '*', 'group': None, 'is_blocking': False}], root='moonshot-v1-32k', parent=None),\n",
       " Model(id='moonshot-v1-128k', created=1626777600, object='model', owned_by='moonshot', permission=[{'id': 'modelperm-LwHkVFn8AcMItP432fKKDIKJ', 'object': 'model_permission', 'created': 1626777600, 'allow_create_engine': True, 'allow_sampling': True, 'allow_logprobs': True, 'allow_search_indices': False, 'allow_view': True, 'allow_fine_tuning': False, 'organization': '*', 'group': None, 'is_blocking': False}], root='moonshot-v1-128k', parent=None),\n",
       " Model(id='Doubao-pro-128k', created=1626777600, object='model', owned_by='doubao', permission=[{'id': 'modelperm-LwHkVFn8AcMItP432fKKDIKJ', 'object': 'model_permission', 'created': 1626777600, 'allow_create_engine': True, 'allow_sampling': True, 'allow_logprobs': True, 'allow_search_indices': False, 'allow_view': True, 'allow_fine_tuning': False, 'organization': '*', 'group': None, 'is_blocking': False}], root='Doubao-pro-128k', parent=None),\n",
       " Model(id='Doubao-pro-32k', created=1626777600, object='model', owned_by='doubao', permission=[{'id': 'modelperm-LwHkVFn8AcMItP432fKKDIKJ', 'object': 'model_permission', 'created': 1626777600, 'allow_create_engine': True, 'allow_sampling': True, 'allow_logprobs': True, 'allow_search_indices': False, 'allow_view': True, 'allow_fine_tuning': False, 'organization': '*', 'group': None, 'is_blocking': False}], root='Doubao-pro-32k', parent=None),\n",
       " Model(id='Doubao-pro-4k', created=1626777600, object='model', owned_by='doubao', permission=[{'id': 'modelperm-LwHkVFn8AcMItP432fKKDIKJ', 'object': 'model_permission', 'created': 1626777600, 'allow_create_engine': True, 'allow_sampling': True, 'allow_logprobs': True, 'allow_search_indices': False, 'allow_view': True, 'allow_fine_tuning': False, 'organization': '*', 'group': None, 'is_blocking': False}], root='Doubao-pro-4k', parent=None),\n",
       " Model(id='Doubao-lite-128k', created=1626777600, object='model', owned_by='doubao', permission=[{'id': 'modelperm-LwHkVFn8AcMItP432fKKDIKJ', 'object': 'model_permission', 'created': 1626777600, 'allow_create_engine': True, 'allow_sampling': True, 'allow_logprobs': True, 'allow_search_indices': False, 'allow_view': True, 'allow_fine_tuning': False, 'organization': '*', 'group': None, 'is_blocking': False}], root='Doubao-lite-128k', parent=None),\n",
       " Model(id='Doubao-lite-32k', created=1626777600, object='model', owned_by='doubao', permission=[{'id': 'modelperm-LwHkVFn8AcMItP432fKKDIKJ', 'object': 'model_permission', 'created': 1626777600, 'allow_create_engine': True, 'allow_sampling': True, 'allow_logprobs': True, 'allow_search_indices': False, 'allow_view': True, 'allow_fine_tuning': False, 'organization': '*', 'group': None, 'is_blocking': False}], root='Doubao-lite-32k', parent=None),\n",
       " Model(id='Doubao-lite-4k', created=1626777600, object='model', owned_by='doubao', permission=[{'id': 'modelperm-LwHkVFn8AcMItP432fKKDIKJ', 'object': 'model_permission', 'created': 1626777600, 'allow_create_engine': True, 'allow_sampling': True, 'allow_logprobs': True, 'allow_search_indices': False, 'allow_view': True, 'allow_fine_tuning': False, 'organization': '*', 'group': None, 'is_blocking': False}], root='Doubao-lite-4k', parent=None),\n",
       " Model(id='mistral-small-latest', created=1626777600, object='model', owned_by='mistralai', permission=[{'id': 'modelperm-LwHkVFn8AcMItP432fKKDIKJ', 'object': 'model_permission', 'created': 1626777600, 'allow_create_engine': True, 'allow_sampling': True, 'allow_logprobs': True, 'allow_search_indices': False, 'allow_view': True, 'allow_fine_tuning': False, 'organization': '*', 'group': None, 'is_blocking': False}], root='mistral-small-latest', parent=None),\n",
       " Model(id='mistral-large-latest', created=1626777600, object='model', owned_by='mistralai', permission=[{'id': 'modelperm-LwHkVFn8AcMItP432fKKDIKJ', 'object': 'model_permission', 'created': 1626777600, 'allow_create_engine': True, 'allow_sampling': True, 'allow_logprobs': True, 'allow_search_indices': False, 'allow_view': True, 'allow_fine_tuning': False, 'organization': '*', 'group': None, 'is_blocking': False}], root='mistral-large-latest', parent=None),\n",
       " Model(id='gemma2-9b-it', created=1626777600, object='model', owned_by='groq', permission=[{'id': 'modelperm-LwHkVFn8AcMItP432fKKDIKJ', 'object': 'model_permission', 'created': 1626777600, 'allow_create_engine': True, 'allow_sampling': True, 'allow_logprobs': True, 'allow_search_indices': False, 'allow_view': True, 'allow_fine_tuning': False, 'organization': '*', 'group': None, 'is_blocking': False}], root='gemma2-9b-it', parent=None),\n",
       " Model(id='llama-3.1-70b-versatile', created=1626777600, object='model', owned_by='groq', permission=[{'id': 'modelperm-LwHkVFn8AcMItP432fKKDIKJ', 'object': 'model_permission', 'created': 1626777600, 'allow_create_engine': True, 'allow_sampling': True, 'allow_logprobs': True, 'allow_search_indices': False, 'allow_view': True, 'allow_fine_tuning': False, 'organization': '*', 'group': None, 'is_blocking': False}], root='llama-3.1-70b-versatile', parent=None),\n",
       " Model(id='llama-3.1-8b-instant', created=1626777600, object='model', owned_by='groq', permission=[{'id': 'modelperm-LwHkVFn8AcMItP432fKKDIKJ', 'object': 'model_permission', 'created': 1626777600, 'allow_create_engine': True, 'allow_sampling': True, 'allow_logprobs': True, 'allow_search_indices': False, 'allow_view': True, 'allow_fine_tuning': False, 'organization': '*', 'group': None, 'is_blocking': False}], root='llama-3.1-8b-instant', parent=None),\n",
       " Model(id='llama-3.2-11b-vision-preview', created=1626777600, object='model', owned_by='groq', permission=[{'id': 'modelperm-LwHkVFn8AcMItP432fKKDIKJ', 'object': 'model_permission', 'created': 1626777600, 'allow_create_engine': True, 'allow_sampling': True, 'allow_logprobs': True, 'allow_search_indices': False, 'allow_view': True, 'allow_fine_tuning': False, 'organization': '*', 'group': None, 'is_blocking': False}], root='llama-3.2-11b-vision-preview', parent=None),\n",
       " Model(id='llama-3.2-1b-preview', created=1626777600, object='model', owned_by='groq', permission=[{'id': 'modelperm-LwHkVFn8AcMItP432fKKDIKJ', 'object': 'model_permission', 'created': 1626777600, 'allow_create_engine': True, 'allow_sampling': True, 'allow_logprobs': True, 'allow_search_indices': False, 'allow_view': True, 'allow_fine_tuning': False, 'organization': '*', 'group': None, 'is_blocking': False}], root='llama-3.2-1b-preview', parent=None),\n",
       " Model(id='llama-3.2-3b-preview', created=1626777600, object='model', owned_by='groq', permission=[{'id': 'modelperm-LwHkVFn8AcMItP432fKKDIKJ', 'object': 'model_permission', 'created': 1626777600, 'allow_create_engine': True, 'allow_sampling': True, 'allow_logprobs': True, 'allow_search_indices': False, 'allow_view': True, 'allow_fine_tuning': False, 'organization': '*', 'group': None, 'is_blocking': False}], root='llama-3.2-3b-preview', parent=None),\n",
       " Model(id='llama-3.2-11b-vision-preview', created=1626777600, object='model', owned_by='groq', permission=[{'id': 'modelperm-LwHkVFn8AcMItP432fKKDIKJ', 'object': 'model_permission', 'created': 1626777600, 'allow_create_engine': True, 'allow_sampling': True, 'allow_logprobs': True, 'allow_search_indices': False, 'allow_view': True, 'allow_fine_tuning': False, 'organization': '*', 'group': None, 'is_blocking': False}], root='llama-3.2-11b-vision-preview', parent=None),\n",
       " Model(id='llama-3.2-90b-vision-preview', created=1626777600, object='model', owned_by='groq', permission=[{'id': 'modelperm-LwHkVFn8AcMItP432fKKDIKJ', 'object': 'model_permission', 'created': 1626777600, 'allow_create_engine': True, 'allow_sampling': True, 'allow_logprobs': True, 'allow_search_indices': False, 'allow_view': True, 'allow_fine_tuning': False, 'organization': '*', 'group': None, 'is_blocking': False}], root='llama-3.2-90b-vision-preview', parent=None),\n",
       " Model(id='llama3-70b-8192', created=1626777600, object='model', owned_by='groq', permission=[{'id': 'modelperm-LwHkVFn8AcMItP432fKKDIKJ', 'object': 'model_permission', 'created': 1626777600, 'allow_create_engine': True, 'allow_sampling': True, 'allow_logprobs': True, 'allow_search_indices': False, 'allow_view': True, 'allow_fine_tuning': False, 'organization': '*', 'group': None, 'is_blocking': False}], root='llama3-70b-8192', parent=None),\n",
       " Model(id='llama3-8b-8192', created=1626777600, object='model', owned_by='groq', permission=[{'id': 'modelperm-LwHkVFn8AcMItP432fKKDIKJ', 'object': 'model_permission', 'created': 1626777600, 'allow_create_engine': True, 'allow_sampling': True, 'allow_logprobs': True, 'allow_search_indices': False, 'allow_view': True, 'allow_fine_tuning': False, 'organization': '*', 'group': None, 'is_blocking': False}], root='llama3-8b-8192', parent=None),\n",
       " Model(id='llama3-groq-8b-8192-tool-use-preview', created=1626777600, object='model', owned_by='groq', permission=[{'id': 'modelperm-LwHkVFn8AcMItP432fKKDIKJ', 'object': 'model_permission', 'created': 1626777600, 'allow_create_engine': True, 'allow_sampling': True, 'allow_logprobs': True, 'allow_search_indices': False, 'allow_view': True, 'allow_fine_tuning': False, 'organization': '*', 'group': None, 'is_blocking': False}], root='llama3-groq-8b-8192-tool-use-preview', parent=None),\n",
       " Model(id='mixtral-8x7b-32768', created=1626777600, object='model', owned_by='groq', permission=[{'id': 'modelperm-LwHkVFn8AcMItP432fKKDIKJ', 'object': 'model_permission', 'created': 1626777600, 'allow_create_engine': True, 'allow_sampling': True, 'allow_logprobs': True, 'allow_search_indices': False, 'allow_view': True, 'allow_fine_tuning': False, 'organization': '*', 'group': None, 'is_blocking': False}], root='mixtral-8x7b-32768', parent=None),\n",
       " Model(id='distil-whisper-large-v3-en', created=1626777600, object='model', owned_by='groq', permission=[{'id': 'modelperm-LwHkVFn8AcMItP432fKKDIKJ', 'object': 'model_permission', 'created': 1626777600, 'allow_create_engine': True, 'allow_sampling': True, 'allow_logprobs': True, 'allow_search_indices': False, 'allow_view': True, 'allow_fine_tuning': False, 'organization': '*', 'group': None, 'is_blocking': False}], root='distil-whisper-large-v3-en', parent=None),\n",
       " Model(id='whisper-large-v3', created=1626777600, object='model', owned_by='groq', permission=[{'id': 'modelperm-LwHkVFn8AcMItP432fKKDIKJ', 'object': 'model_permission', 'created': 1626777600, 'allow_create_engine': True, 'allow_sampling': True, 'allow_logprobs': True, 'allow_search_indices': False, 'allow_view': True, 'allow_fine_tuning': False, 'organization': '*', 'group': None, 'is_blocking': False}], root='whisper-large-v3', parent=None),\n",
       " Model(id='whisper-large-v3-turbo', created=1626777600, object='model', owned_by='groq', permission=[{'id': 'modelperm-LwHkVFn8AcMItP432fKKDIKJ', 'object': 'model_permission', 'created': 1626777600, 'allow_create_engine': True, 'allow_sampling': True, 'allow_logprobs': True, 'allow_search_indices': False, 'allow_view': True, 'allow_fine_tuning': False, 'organization': '*', 'group': None, 'is_blocking': False}], root='whisper-large-v3-turbo', parent=None),\n",
       " Model(id='yi-34b-chat-0205', created=1626777600, object='model', owned_by='lingyiwanwu', permission=[{'id': 'modelperm-LwHkVFn8AcMItP432fKKDIKJ', 'object': 'model_permission', 'created': 1626777600, 'allow_create_engine': True, 'allow_sampling': True, 'allow_logprobs': True, 'allow_search_indices': False, 'allow_view': True, 'allow_fine_tuning': False, 'organization': '*', 'group': None, 'is_blocking': False}], root='yi-34b-chat-0205', parent=None),\n",
       " Model(id='yi-34b-chat-200k', created=1626777600, object='model', owned_by='lingyiwanwu', permission=[{'id': 'modelperm-LwHkVFn8AcMItP432fKKDIKJ', 'object': 'model_permission', 'created': 1626777600, 'allow_create_engine': True, 'allow_sampling': True, 'allow_logprobs': True, 'allow_search_indices': False, 'allow_view': True, 'allow_fine_tuning': False, 'organization': '*', 'group': None, 'is_blocking': False}], root='yi-34b-chat-200k', parent=None),\n",
       " Model(id='yi-vl-plus', created=1626777600, object='model', owned_by='lingyiwanwu', permission=[{'id': 'modelperm-LwHkVFn8AcMItP432fKKDIKJ', 'object': 'model_permission', 'created': 1626777600, 'allow_create_engine': True, 'allow_sampling': True, 'allow_logprobs': True, 'allow_search_indices': False, 'allow_view': True, 'allow_fine_tuning': False, 'organization': '*', 'group': None, 'is_blocking': False}], root='yi-vl-plus', parent=None),\n",
       " Model(id='step-2-16k', created=1626777600, object='model', owned_by='stepfun', permission=[{'id': 'modelperm-LwHkVFn8AcMItP432fKKDIKJ', 'object': 'model_permission', 'created': 1626777600, 'allow_create_engine': True, 'allow_sampling': True, 'allow_logprobs': True, 'allow_search_indices': False, 'allow_view': True, 'allow_fine_tuning': False, 'organization': '*', 'group': None, 'is_blocking': False}], root='step-2-16k', parent=None),\n",
       " Model(id='deepseek-chat', created=1626777600, object='model', owned_by='deepseek', permission=[{'id': 'modelperm-LwHkVFn8AcMItP432fKKDIKJ', 'object': 'model_permission', 'created': 1626777600, 'allow_create_engine': True, 'allow_sampling': True, 'allow_logprobs': True, 'allow_search_indices': False, 'allow_view': True, 'allow_fine_tuning': False, 'organization': '*', 'group': None, 'is_blocking': False}], root='deepseek-chat', parent=None),\n",
       " Model(id='THUDM/chatglm3-6b', created=1626777600, object='model', owned_by='siliconflow', permission=[{'id': 'modelperm-LwHkVFn8AcMItP432fKKDIKJ', 'object': 'model_permission', 'created': 1626777600, 'allow_create_engine': True, 'allow_sampling': True, 'allow_logprobs': True, 'allow_search_indices': False, 'allow_view': True, 'allow_fine_tuning': False, 'organization': '*', 'group': None, 'is_blocking': False}], root='THUDM/chatglm3-6b', parent=None),\n",
       " Model(id='deepseek-ai/DeepSeek-V2-Chat', created=1626777600, object='model', owned_by='siliconflow', permission=[{'id': 'modelperm-LwHkVFn8AcMItP432fKKDIKJ', 'object': 'model_permission', 'created': 1626777600, 'allow_create_engine': True, 'allow_sampling': True, 'allow_logprobs': True, 'allow_search_indices': False, 'allow_view': True, 'allow_fine_tuning': False, 'organization': '*', 'group': None, 'is_blocking': False}], root='deepseek-ai/DeepSeek-V2-Chat', parent=None),\n",
       " Model(id='THUDM/glm-4-9b-chat', created=1626777600, object='model', owned_by='siliconflow', permission=[{'id': 'modelperm-LwHkVFn8AcMItP432fKKDIKJ', 'object': 'model_permission', 'created': 1626777600, 'allow_create_engine': True, 'allow_sampling': True, 'allow_logprobs': True, 'allow_search_indices': False, 'allow_view': True, 'allow_fine_tuning': False, 'organization': '*', 'group': None, 'is_blocking': False}], root='THUDM/glm-4-9b-chat', parent=None),\n",
       " Model(id='Qwen/Qwen2-72B-Instruct', created=1626777600, object='model', owned_by='siliconflow', permission=[{'id': 'modelperm-LwHkVFn8AcMItP432fKKDIKJ', 'object': 'model_permission', 'created': 1626777600, 'allow_create_engine': True, 'allow_sampling': True, 'allow_logprobs': True, 'allow_search_indices': False, 'allow_view': True, 'allow_fine_tuning': False, 'organization': '*', 'group': None, 'is_blocking': False}], root='Qwen/Qwen2-72B-Instruct', parent=None),\n",
       " Model(id='Qwen/Qwen2-7B-Instruct', created=1626777600, object='model', owned_by='siliconflow', permission=[{'id': 'modelperm-LwHkVFn8AcMItP432fKKDIKJ', 'object': 'model_permission', 'created': 1626777600, 'allow_create_engine': True, 'allow_sampling': True, 'allow_logprobs': True, 'allow_search_indices': False, 'allow_view': True, 'allow_fine_tuning': False, 'organization': '*', 'group': None, 'is_blocking': False}], root='Qwen/Qwen2-7B-Instruct', parent=None),\n",
       " Model(id='deepseek-ai/DeepSeek-Coder-V2-Instruct', created=1626777600, object='model', owned_by='siliconflow', permission=[{'id': 'modelperm-LwHkVFn8AcMItP432fKKDIKJ', 'object': 'model_permission', 'created': 1626777600, 'allow_create_engine': True, 'allow_sampling': True, 'allow_logprobs': True, 'allow_search_indices': False, 'allow_view': True, 'allow_fine_tuning': False, 'organization': '*', 'group': None, 'is_blocking': False}], root='deepseek-ai/DeepSeek-Coder-V2-Instruct', parent=None),\n",
       " Model(id='Baichuan4-Air', created=1626777600, object='model', owned_by='custom', permission=None, root='Baichuan4-Air', parent=None),\n",
       " Model(id='Baichuan4-Turbo', created=1626777600, object='model', owned_by='custom', permission=None, root='Baichuan4-Turbo', parent=None),\n",
       " Model(id='DeepSeek-R1', created=1626777600, object='model', owned_by='custom', permission=None, root='DeepSeek-R1', parent=None),\n",
       " Model(id='Gryphe/MythoMax-L2-13b', created=1626777600, object='model', owned_by='custom', permission=None, root='Gryphe/MythoMax-L2-13b', parent=None),\n",
       " Model(id='Qwen/Qwen2.5-7B-Instruct', created=1626777600, object='model', owned_by='custom', permission=None, root='Qwen/Qwen2.5-7B-Instruct', parent=None),\n",
       " Model(id='ahm-Phi-3-5-mini-instruct', created=1626777600, object='model', owned_by='custom', permission=None, root='ahm-Phi-3-5-mini-instruct', parent=None),\n",
       " Model(id='aihub-Phi-4-mini-instruct', created=1626777600, object='model', owned_by='custom', permission=None, root='aihub-Phi-4-mini-instruct', parent=None),\n",
       " Model(id='claude-3-7-sonnet-latest', created=1626777600, object='model', owned_by='custom', permission=None, root='claude-3-7-sonnet-latest', parent=None),\n",
       " Model(id='Doubao-pro-256k', created=1626777600, object='model', owned_by='custom', permission=None, root='Doubao-pro-256k', parent=None),\n",
       " Model(id='gemini-1.5-pro-exp-0801', created=1626777600, object='model', owned_by='custom', permission=None, root='gemini-1.5-pro-exp-0801', parent=None),\n",
       " Model(id='gemini-exp-1121', created=1626777600, object='model', owned_by='custom', permission=None, root='gemini-exp-1121', parent=None),\n",
       " Model(id='llama-3.3-70b-versatile', created=1626777600, object='model', owned_by='custom', permission=None, root='llama-3.3-70b-versatile', parent=None),\n",
       " Model(id='Qwen/Qwen2.5-32B-Instruct', created=1626777600, object='model', owned_by='custom', permission=None, root='Qwen/Qwen2.5-32B-Instruct', parent=None),\n",
       " Model(id='kimi-latest', created=1626777600, object='model', owned_by='custom', permission=None, root='kimi-latest', parent=None),\n",
       " Model(id='grok-beta', created=1626777600, object='model', owned_by='custom', permission=None, root='grok-beta', parent=None),\n",
       " Model(id='Doubao-1.5-pro-256k', created=1626777600, object='model', owned_by='custom', permission=None, root='Doubao-1.5-pro-256k', parent=None),\n",
       " Model(id='gemini-2.0-flash-lite-preview-02-05', created=1626777600, object='model', owned_by='custom', permission=None, root='gemini-2.0-flash-lite-preview-02-05', parent=None),\n",
       " Model(id='aihubmix-Mistral-Large-2411', created=1626777600, object='model', owned_by='custom', permission=None, root='aihubmix-Mistral-Large-2411', parent=None),\n",
       " Model(id='deepseek-ai/DeepSeek-R1-Distill-Llama-70B', created=1626777600, object='model', owned_by='custom', permission=None, root='deepseek-ai/DeepSeek-R1-Distill-Llama-70B', parent=None),\n",
       " Model(id='gpt-4o-audio-preview-2024-10-01', created=1626777600, object='model', owned_by='custom', permission=None, root='gpt-4o-audio-preview-2024-10-01', parent=None),\n",
       " Model(id='aihubmix-Codestral-2501', created=1626777600, object='model', owned_by='custom', permission=None, root='aihubmix-Codestral-2501', parent=None),\n",
       " Model(id='aihubmix-Llama-3-1-70B-Instruct', created=1626777600, object='model', owned_by='custom', permission=None, root='aihubmix-Llama-3-1-70B-Instruct', parent=None),\n",
       " Model(id='grok-vision-beta', created=1626777600, object='model', owned_by='custom', permission=None, root='grok-vision-beta', parent=None),\n",
       " Model(id='gemini-2.0-pro-exp-02-05-search', created=1626777600, object='model', owned_by='custom', permission=None, root='gemini-2.0-pro-exp-02-05-search', parent=None),\n",
       " Model(id='Baichuan3-Turbo-128k', created=1626777600, object='model', owned_by='custom', permission=None, root='Baichuan3-Turbo-128k', parent=None),\n",
       " Model(id='gemini-2.0-flash-exp-search', created=1626777600, object='model', owned_by='custom', permission=None, root='gemini-2.0-flash-exp-search', parent=None),\n",
       " Model(id='gemini-1.5-flash-8b-exp-0827', created=1626777600, object='model', owned_by='custom', permission=None, root='gemini-1.5-flash-8b-exp-0827', parent=None),\n",
       " Model(id='MiniMax-Text-01', created=1626777600, object='model', owned_by='custom', permission=None, root='MiniMax-Text-01', parent=None),\n",
       " Model(id='Mistral-large-2407', created=1626777600, object='model', owned_by='custom', permission=None, root='Mistral-large-2407', parent=None),\n",
       " Model(id='aihubmix-Cohere-command-r', created=1626777600, object='model', owned_by='custom', permission=None, root='aihubmix-Cohere-command-r', parent=None),\n",
       " Model(id='command-r-plus-08-2024', created=1626777600, object='model', owned_by='custom', permission=None, root='command-r-plus-08-2024', parent=None),\n",
       " Model(id='deepseek-ai/DeepSeek-R1-Distill-Qwen-32B', created=1626777600, object='model', owned_by='custom', permission=None, root='deepseek-ai/DeepSeek-R1-Distill-Qwen-32B', parent=None),\n",
       " Model(id='gemini-2.0-flash', created=1626777600, object='model', owned_by='custom', permission=None, root='gemini-2.0-flash', parent=None),\n",
       " Model(id='gemini-2.0-pro-exp-02-05', created=1626777600, object='model', owned_by='custom', permission=None, root='gemini-2.0-pro-exp-02-05', parent=None),\n",
       " Model(id='Doubao-1.5-pro-32k', created=1626777600, object='model', owned_by='custom', permission=None, root='Doubao-1.5-pro-32k', parent=None),\n",
       " Model(id='codestral-latest', created=1626777600, object='model', owned_by='custom', permission=None, root='codestral-latest', parent=None),\n",
       " Model(id='command-r-08-2024', created=1626777600, object='model', owned_by='custom', permission=None, root='command-r-08-2024', parent=None),\n",
       " Model(id='gemini-exp-1114', created=1626777600, object='model', owned_by='custom', permission=None, root='gemini-exp-1114', parent=None),\n",
       " Model(id='Doubao-1.5-lite-32k', created=1626777600, object='model', owned_by='custom', permission=None, root='Doubao-1.5-lite-32k', parent=None),\n",
       " Model(id='aihubmix-Jamba-1-5-Large', created=1626777600, object='model', owned_by='custom', permission=None, root='aihubmix-Jamba-1-5-Large', parent=None),\n",
       " Model(id='aihubmix-Llama-3-3-70B-Instruct', created=1626777600, object='model', owned_by='custom', permission=None, root='aihubmix-Llama-3-3-70B-Instruct', parent=None),\n",
       " Model(id='DeepSeek-V3', created=1626777600, object='model', owned_by='custom', permission=None, root='DeepSeek-V3', parent=None),\n",
       " Model(id='gemini-2.0-flash-lite', created=1626777600, object='model', owned_by='custom', permission=None, root='gemini-2.0-flash-lite', parent=None),\n",
       " Model(id='aihubmix-Llama-3-1-405B-Instruct', created=1626777600, object='model', owned_by='custom', permission=None, root='aihubmix-Llama-3-1-405B-Instruct', parent=None),\n",
       " Model(id='moonshot-v1-128k-vision-preview', created=1626777600, object='model', owned_by='custom', permission=None, root='moonshot-v1-128k-vision-preview', parent=None),\n",
       " Model(id='deepseek-ai/deepseek-vl2', created=1626777600, object='model', owned_by='custom', permission=None, root='deepseek-ai/deepseek-vl2', parent=None),\n",
       " Model(id='llama-3.1-70b', created=1626777600, object='model', owned_by='custom', permission=None, root='llama-3.1-70b', parent=None),\n",
       " Model(id='text-moderation-latest\\t', created=1626777600, object='model', owned_by='custom', permission=None, root='text-moderation-latest\\t', parent=None),\n",
       " Model(id='aihubmix-DeepSeek-R1', created=1626777600, object='model', owned_by='custom', permission=None, root='aihubmix-DeepSeek-R1', parent=None),\n",
       " Model(id='aihubmix-Llama-3-2-11B-Vision', created=1626777600, object='model', owned_by='custom', permission=None, root='aihubmix-Llama-3-2-11B-Vision', parent=None),\n",
       " Model(id='aihubmix-Mistral-large', created=1626777600, object='model', owned_by='custom', permission=None, root='aihubmix-Mistral-large', parent=None),\n",
       " Model(id='deepseek-ai/DeepSeek-R1-Distill-Qwen-14B', created=1626777600, object='model', owned_by='custom', permission=None, root='deepseek-ai/DeepSeek-R1-Distill-Qwen-14B', parent=None),\n",
       " Model(id='yi-lightning', created=1626777600, object='model', owned_by='custom', permission=None, root='yi-lightning', parent=None),\n",
       " Model(id='glm-zero-preview', created=1626777600, object='model', owned_by='custom', permission=None, root='glm-zero-preview', parent=None),\n",
       " Model(id='aihubmix-Llama-3-70B-Instruct', created=1626777600, object='model', owned_by='custom', permission=None, root='aihubmix-Llama-3-70B-Instruct', parent=None),\n",
       " Model(id='gpt-4.5-preview', created=1626777600, object='model', owned_by='custom', permission=None, root='gpt-4.5-preview', parent=None),\n",
       " Model(id='llama-3.1-405b-instruct', created=1626777600, object='model', owned_by='custom', permission=None, root='llama-3.1-405b-instruct', parent=None),\n",
       " Model(id='yi-large-rag', created=1626777600, object='model', owned_by='custom', permission=None, root='yi-large-rag', parent=None),\n",
       " Model(id='glm-4-plus', created=1626777600, object='model', owned_by='custom', permission=None, root='glm-4-plus', parent=None),\n",
       " Model(id='aihubmix-Mistral-large-2407', created=1626777600, object='model', owned_by='custom', permission=None, root='aihubmix-Mistral-large-2407', parent=None),\n",
       " Model(id='deepseek-r1-distill-llama-70b', created=1626777600, object='model', owned_by='custom', permission=None, root='deepseek-r1-distill-llama-70b', parent=None),\n",
       " Model(id='nvidia/llama-3.1-nemotron-70b-instruct', created=1626777600, object='model', owned_by='custom', permission=None, root='nvidia/llama-3.1-nemotron-70b-instruct', parent=None),\n",
       " Model(id='yi-medium', created=1626777600, object='model', owned_by='custom', permission=None, root='yi-medium', parent=None),\n",
       " Model(id='ahm-Phi-3-5-vision-instruct', created=1626777600, object='model', owned_by='custom', permission=None, root='ahm-Phi-3-5-vision-instruct', parent=None),\n",
       " Model(id='aihub-Phi-4-multimodal-instruct', created=1626777600, object='model', owned_by='custom', permission=None, root='aihub-Phi-4-multimodal-instruct', parent=None),\n",
       " Model(id='aihubmix-Llama-3-2-90B-Vision', created=1626777600, object='model', owned_by='custom', permission=None, root='aihubmix-Llama-3-2-90B-Vision', parent=None),\n",
       " Model(id='deepseek-ai/DeepSeek-R1', created=1626777600, object='model', owned_by='custom', permission=None, root='deepseek-ai/DeepSeek-R1', parent=None),\n",
       " Model(id='deepseek-ai/DeepSeek-V3', created=1626777600, object='model', owned_by='custom', permission=None, root='deepseek-ai/DeepSeek-V3', parent=None),\n",
       " Model(id='qwen-qwq-32b', created=1626777600, object='model', owned_by='custom', permission=None, root='qwen-qwq-32b', parent=None),\n",
       " Model(id='claude-3-5-haiku-latest', created=1626777600, object='model', owned_by='custom', permission=None, root='claude-3-5-haiku-latest', parent=None),\n",
       " Model(id='qwen-turbo-2024-11-01', created=1626777600, object='model', owned_by='custom', permission=None, root='qwen-turbo-2024-11-01', parent=None),\n",
       " Model(id='qwen2.5-vl-72b-instruct', created=1626777600, object='model', owned_by='custom', permission=None, root='qwen2.5-vl-72b-instruct', parent=None),\n",
       " Model(id='yi-large', created=1626777600, object='model', owned_by='custom', permission=None, root='yi-large', parent=None),\n",
       " Model(id='Qwen/QwQ-32B', created=1626777600, object='model', owned_by='custom', permission=None, root='Qwen/QwQ-32B', parent=None),\n",
       " Model(id='anthropic-3-7-sonnet-20250219', created=1626777600, object='model', owned_by='custom', permission=None, root='anthropic-3-7-sonnet-20250219', parent=None),\n",
       " Model(id='grok-2-vision-1212', created=1626777600, object='model', owned_by='custom', permission=None, root='grok-2-vision-1212', parent=None),\n",
       " Model(id='learnlm-1.5-pro-experimental', created=1626777600, object='model', owned_by='custom', permission=None, root='learnlm-1.5-pro-experimental', parent=None),\n",
       " Model(id='qwen-max-0125', created=1626777600, object='model', owned_by='custom', permission=None, root='qwen-max-0125', parent=None),\n",
       " Model(id='aihubmix-command-r-plus', created=1626777600, object='model', owned_by='custom', permission=None, root='aihubmix-command-r-plus', parent=None),\n",
       " Model(id='google/gemma-2-27b-it', created=1626777600, object='model', owned_by='custom', permission=None, root='google/gemma-2-27b-it', parent=None),\n",
       " Model(id='gpt-4o-audio-preview', created=1626777600, object='model', owned_by='custom', permission=None, root='gpt-4o-audio-preview', parent=None),\n",
       " Model(id='moonshot-v1-32k-vision-preview', created=1626777600, object='model', owned_by='custom', permission=None, root='moonshot-v1-32k-vision-preview', parent=None),\n",
       " Model(id='ahm-Phi-3-medium-128k', created=1626777600, object='model', owned_by='custom', permission=None, root='ahm-Phi-3-medium-128k', parent=None),\n",
       " Model(id='aihubmix-command-r-08-2024', created=1626777600, object='model', owned_by='custom', permission=None, root='aihubmix-command-r-08-2024', parent=None),\n",
       " Model(id='WizardLM/WizardCoder-Python-34B-V1.0', created=1626777600, object='model', owned_by='custom', permission=None, root='WizardLM/WizardCoder-Python-34B-V1.0', parent=None),\n",
       " Model(id='aihub-Phi-4', created=1626777600, object='model', owned_by='custom', permission=None, root='aihub-Phi-4', parent=None),\n",
       " Model(id='aihubmix-command-r-plus-08-2024', created=1626777600, object='model', owned_by='custom', permission=None, root='aihubmix-command-r-plus-08-2024', parent=None),\n",
       " Model(id='gpt-4.5-preview-2025-02-27', created=1626777600, object='model', owned_by='custom', permission=None, root='gpt-4.5-preview-2025-02-27', parent=None),\n",
       " Model(id='deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B', created=1626777600, object='model', owned_by='custom', permission=None, root='deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B', parent=None),\n",
       " Model(id='Qwen/Qwen2.5-72B-Instruct', created=1626777600, object='model', owned_by='custom', permission=None, root='Qwen/Qwen2.5-72B-Instruct', parent=None),\n",
       " Model(id='anthropic-3-5-sonnet-20241022', created=1626777600, object='model', owned_by='custom', permission=None, root='anthropic-3-5-sonnet-20241022', parent=None),\n",
       " Model(id='gpt-4o-zh', created=1626777600, object='model', owned_by='custom', permission=None, root='gpt-4o-zh', parent=None),\n",
       " Model(id='omni-moderation-latest', created=1626777600, object='model', owned_by='custom', permission=None, root='omni-moderation-latest', parent=None),\n",
       " Model(id='gemini-exp-1206', created=1626777600, object='model', owned_by='custom', permission=None, root='gemini-exp-1206', parent=None),\n",
       " Model(id='Qwen/QVQ-72B-Preview', created=1626777600, object='model', owned_by='custom', permission=None, root='Qwen/QVQ-72B-Preview', parent=None),\n",
       " Model(id='cogview-3-plus', created=1626777600, object='model', owned_by='custom', permission=None, root='cogview-3-plus', parent=None),\n",
       " Model(id='deepseek-ai/Janus-Pro-7B', created=1626777600, object='model', owned_by='custom', permission=None, root='deepseek-ai/Janus-Pro-7B', parent=None),\n",
       " Model(id='aihubmix-Llama-3-1-8B-Instruct', created=1626777600, object='model', owned_by='custom', permission=None, root='aihubmix-Llama-3-1-8B-Instruct', parent=None),\n",
       " Model(id='Baichuan3-Turbo', created=1626777600, object='model', owned_by='custom', permission=None, root='Baichuan3-Turbo', parent=None),\n",
       " Model(id='Qwen/Qwen2.5-Coder-32B-Instruct', created=1626777600, object='model', owned_by='custom', permission=None, root='Qwen/Qwen2.5-Coder-32B-Instruct', parent=None),\n",
       " Model(id='glm-4-flash', created=1626777600, object='model', owned_by='custom', permission=None, root='glm-4-flash', parent=None),\n",
       " Model(id='moonshot-v1-8k-vision-preview', created=1626777600, object='model', owned_by='custom', permission=None, root='moonshot-v1-8k-vision-preview', parent=None),\n",
       " Model(id='qwen-long', created=1626777600, object='model', owned_by='custom', permission=None, root='qwen-long', parent=None),\n",
       " Model(id='gemini-2.0-flash-search', created=1626777600, object='model', owned_by='custom', permission=None, root='gemini-2.0-flash-search', parent=None),\n",
       " Model(id='microsoft/WizardLM-2-8x22B', created=1626777600, object='model', owned_by='custom', permission=None, root='microsoft/WizardLM-2-8x22B', parent=None),\n",
       " Model(id='Doubao-1.5-vision-pro-32k', created=1626777600, object='model', owned_by='custom', permission=None, root='Doubao-1.5-vision-pro-32k', parent=None),\n",
       " Model(id='Qwen/Qwen2.5-72B-Instruct-128K', created=1626777600, object='model', owned_by='custom', permission=None, root='Qwen/Qwen2.5-72B-Instruct-128K', parent=None),\n",
       " Model(id='deepseek-ai/DeepSeek-R1-Distill-Qwen-7B', created=1626777600, object='model', owned_by='custom', permission=None, root='deepseek-ai/DeepSeek-R1-Distill-Qwen-7B', parent=None),\n",
       " Model(id='gemini-1.5-flash-exp-0827', created=1626777600, object='model', owned_by='custom', permission=None, root='gemini-1.5-flash-exp-0827', parent=None),\n",
       " Model(id='gemini-2.0-flash-thinking-exp-01-21', created=1626777600, object='model', owned_by='custom', permission=None, root='gemini-2.0-flash-thinking-exp-01-21', parent=None),\n",
       " Model(id='anthropic-3-5-sonnet-20240620', created=1626777600, object='model', owned_by='custom', permission=None, root='anthropic-3-5-sonnet-20240620', parent=None),\n",
       " Model(id='deepseek-ai/DeepSeek-R1-Zero', created=1626777600, object='model', owned_by='custom', permission=None, root='deepseek-ai/DeepSeek-R1-Zero', parent=None),\n",
       " Model(id='meta-llama/Llama-3.2-90B-Vision-Instruct', created=1626777600, object='model', owned_by='custom', permission=None, root='meta-llama/Llama-3.2-90B-Vision-Instruct', parent=None),\n",
       " Model(id='Qwen/QwQ-32B-Preview', created=1626777600, object='model', owned_by='custom', permission=None, root='Qwen/QwQ-32B-Preview', parent=None),\n",
       " Model(id='Baichuan4', created=1626777600, object='model', owned_by='custom', permission=None, root='Baichuan4', parent=None),\n",
       " Model(id='ahm-Phi-3-medium-4k', created=1626777600, object='model', owned_by='custom', permission=None, root='ahm-Phi-3-medium-4k', parent=None),\n",
       " Model(id='ahm-Phi-3-small-128k', created=1626777600, object='model', owned_by='custom', permission=None, root='ahm-Phi-3-small-128k', parent=None),\n",
       " Model(id='grok-2-1212', created=1626777600, object='model', owned_by='custom', permission=None, root='grok-2-1212', parent=None),\n",
       " Model(id='ahm-Phi-3-5-MoE-instruct', created=1626777600, object='model', owned_by='custom', permission=None, root='ahm-Phi-3-5-MoE-instruct', parent=None),\n",
       " Model(id='deepseek-ai/DeepSeek-R1-Distill-Llama-8B', created=1626777600, object='model', owned_by='custom', permission=None, root='deepseek-ai/DeepSeek-R1-Distill-Llama-8B', parent=None),\n",
       " Model(id='yi-large-turbo', created=1626777600, object='model', owned_by='custom', permission=None, root='yi-large-turbo', parent=None),\n",
       " Model(id='deepseek-ai/DeepSeek-V2.5', created=1626777600, object='model', owned_by='custom', permission=None, root='deepseek-ai/DeepSeek-V2.5', parent=None),\n",
       " Model(id='gemini-2.0-flash-thinking-exp-1219', created=1626777600, object='model', owned_by='custom', permission=None, root='gemini-2.0-flash-thinking-exp-1219', parent=None),\n",
       " Model(id='o3-mini', created=1626777600, object='model', owned_by='custom', permission=None, root='o3-mini', parent=None),\n",
       " Model(id='gemini-1.5-pro-exp-0827', created=1626777600, object='model', owned_by='custom', permission=None, root='gemini-1.5-pro-exp-0827', parent=None)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models.data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774e3a12-01f6-44ad-8829-03510f5d9df6",
   "metadata": {},
   "source": [
    "### 获取模型 ID 列表\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd351597-b055-4d30-aa0b-b5e468f7b924",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gpt-3.5-turbo'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models.data[0].id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fdb8752e-bcb8-4732-a037-1835861c20a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = [model.id for model in models.data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3372f33d-4302-4fc6-9eac-e1d34cf216be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gpt-3.5-turbo', 'gpt-3.5-turbo-0613', 'gpt-3.5-turbo-1106', 'gpt-3.5-turbo-0125', 'gpt-3.5-turbo-16k', 'gpt-3.5-turbo-instruct', 'gpt-4', 'gpt-4-0613', 'gpt-4-1106-preview', 'gpt-4-0125-preview', 'gpt-4-32k', 'gpt-4-turbo-preview', 'gpt-4-turbo', 'gpt-4-turbo-2024-04-09', 'gpt-4o', 'gpt-4o-2024-05-13', 'gpt-4o-2024-08-06', 'gpt-4o-2024-11-20', 'chatgpt-4o-latest', 'gpt-4o-mini', 'gpt-4o-mini-2024-07-18', 'gpt-4-vision-preview', 'text-embedding-ada-002', 'text-embedding-3-small', 'text-embedding-3-large', 'text-curie-001', 'text-babbage-001', 'text-ada-001', 'text-davinci-002', 'text-davinci-003', 'text-moderation-latest', 'text-moderation-stable', 'text-davinci-edit-001', 'davinci-002', 'babbage-002', 'dall-e-2', 'dall-e-3', 'whisper-1', 'tts-1', 'tts-1-hd', 'o1', 'o1-2024-12-17', 'o1-preview', 'o1-preview-2024-09-12', 'o1-mini', 'o1-mini-2024-09-12', 'claude-3-haiku-20240307', 'claude-3-5-haiku-20241022', 'claude-3-sonnet-20240229', 'claude-3-opus-20240229', 'claude-3-5-sonnet-20240620', 'claude-3-5-sonnet-20241022', 'claude-3-5-sonnet-latest', 'glm-4', 'glm-3-turbo', 'qwen-turbo', 'qwen-plus', 'qwen-max', 'qwen-max-longcontext', 'qwen2.5-72b-instruct', 'qwen2.5-32b-instruct', 'qwen2.5-14b-instruct', 'qwen2.5-7b-instruct', 'qwen2.5-3b-instruct', 'qwen2.5-math-72b-instruct', 'qwen2.5-math-7b-instruct', 'qwen2.5-coder-7b-instruct', 'qwen2.5-coder-1.5b-instruct', 'gemini-pro', 'gemini-1.5-flash', 'gemini-1.5-pro', 'gemini-2.0-flash-exp', 'gemini-2.0-flash-thinking-exp', 'claude-3-5-haiku-20241022', 'claude-3-5-sonnet-20240620', 'claude-3-5-sonnet-20241022', 'claude-3-opus-20240229', 'claude-3-7-sonnet-20250219', 'llama3-8b-8192', 'claude-3-haiku-20240307', 'claude-3-sonnet-20240229', 'claude-3-5-sonnet-latest', 'llama3-70b-8192', 'command', 'command-nightly', 'command-light', 'command-light-nightly', 'command-r', 'command-r-plus', 'claude-3-5-sonnet@20240620', 'gemini-pro', 'gemini-1.5-pro-002', 'gemini-1.5-flash-002', 'gemini-2.0-flash-exp', 'gemini-2.0-flash-thinking-exp', 'moonshot-v1-8k', 'moonshot-v1-32k', 'moonshot-v1-128k', 'Doubao-pro-128k', 'Doubao-pro-32k', 'Doubao-pro-4k', 'Doubao-lite-128k', 'Doubao-lite-32k', 'Doubao-lite-4k', 'mistral-small-latest', 'mistral-large-latest', 'gemma2-9b-it', 'llama-3.1-70b-versatile', 'llama-3.1-8b-instant', 'llama-3.2-11b-vision-preview', 'llama-3.2-1b-preview', 'llama-3.2-3b-preview', 'llama-3.2-11b-vision-preview', 'llama-3.2-90b-vision-preview', 'llama3-70b-8192', 'llama3-8b-8192', 'llama3-groq-8b-8192-tool-use-preview', 'mixtral-8x7b-32768', 'distil-whisper-large-v3-en', 'whisper-large-v3', 'whisper-large-v3-turbo', 'yi-34b-chat-0205', 'yi-34b-chat-200k', 'yi-vl-plus', 'step-2-16k', 'deepseek-chat', 'THUDM/chatglm3-6b', 'deepseek-ai/DeepSeek-V2-Chat', 'THUDM/glm-4-9b-chat', 'Qwen/Qwen2-72B-Instruct', 'Qwen/Qwen2-7B-Instruct', 'deepseek-ai/DeepSeek-Coder-V2-Instruct', 'Baichuan4-Air', 'Baichuan4-Turbo', 'DeepSeek-R1', 'Gryphe/MythoMax-L2-13b', 'Qwen/Qwen2.5-7B-Instruct', 'ahm-Phi-3-5-mini-instruct', 'aihub-Phi-4-mini-instruct', 'claude-3-7-sonnet-latest', 'Doubao-pro-256k', 'gemini-1.5-pro-exp-0801', 'gemini-exp-1121', 'llama-3.3-70b-versatile', 'Qwen/Qwen2.5-32B-Instruct', 'kimi-latest', 'grok-beta', 'Doubao-1.5-pro-256k', 'gemini-2.0-flash-lite-preview-02-05', 'aihubmix-Mistral-Large-2411', 'deepseek-ai/DeepSeek-R1-Distill-Llama-70B', 'gpt-4o-audio-preview-2024-10-01', 'aihubmix-Codestral-2501', 'aihubmix-Llama-3-1-70B-Instruct', 'grok-vision-beta', 'gemini-2.0-pro-exp-02-05-search', 'Baichuan3-Turbo-128k', 'gemini-2.0-flash-exp-search', 'gemini-1.5-flash-8b-exp-0827', 'MiniMax-Text-01', 'Mistral-large-2407', 'aihubmix-Cohere-command-r', 'command-r-plus-08-2024', 'deepseek-ai/DeepSeek-R1-Distill-Qwen-32B', 'gemini-2.0-flash', 'gemini-2.0-pro-exp-02-05', 'Doubao-1.5-pro-32k', 'codestral-latest', 'command-r-08-2024', 'gemini-exp-1114', 'Doubao-1.5-lite-32k', 'aihubmix-Jamba-1-5-Large', 'aihubmix-Llama-3-3-70B-Instruct', 'DeepSeek-V3', 'gemini-2.0-flash-lite', 'aihubmix-Llama-3-1-405B-Instruct', 'moonshot-v1-128k-vision-preview', 'deepseek-ai/deepseek-vl2', 'llama-3.1-70b', 'text-moderation-latest\\t', 'aihubmix-DeepSeek-R1', 'aihubmix-Llama-3-2-11B-Vision', 'aihubmix-Mistral-large', 'deepseek-ai/DeepSeek-R1-Distill-Qwen-14B', 'yi-lightning', 'glm-zero-preview', 'aihubmix-Llama-3-70B-Instruct', 'gpt-4.5-preview', 'llama-3.1-405b-instruct', 'yi-large-rag', 'glm-4-plus', 'aihubmix-Mistral-large-2407', 'deepseek-r1-distill-llama-70b', 'nvidia/llama-3.1-nemotron-70b-instruct', 'yi-medium', 'ahm-Phi-3-5-vision-instruct', 'aihub-Phi-4-multimodal-instruct', 'aihubmix-Llama-3-2-90B-Vision', 'deepseek-ai/DeepSeek-R1', 'deepseek-ai/DeepSeek-V3', 'qwen-qwq-32b', 'claude-3-5-haiku-latest', 'qwen-turbo-2024-11-01', 'qwen2.5-vl-72b-instruct', 'yi-large', 'Qwen/QwQ-32B', 'anthropic-3-7-sonnet-20250219', 'grok-2-vision-1212', 'learnlm-1.5-pro-experimental', 'qwen-max-0125', 'aihubmix-command-r-plus', 'google/gemma-2-27b-it', 'gpt-4o-audio-preview', 'moonshot-v1-32k-vision-preview', 'ahm-Phi-3-medium-128k', 'aihubmix-command-r-08-2024', 'WizardLM/WizardCoder-Python-34B-V1.0', 'aihub-Phi-4', 'aihubmix-command-r-plus-08-2024', 'gpt-4.5-preview-2025-02-27', 'deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B', 'Qwen/Qwen2.5-72B-Instruct', 'anthropic-3-5-sonnet-20241022', 'gpt-4o-zh', 'omni-moderation-latest', 'gemini-exp-1206', 'Qwen/QVQ-72B-Preview', 'cogview-3-plus', 'deepseek-ai/Janus-Pro-7B', 'aihubmix-Llama-3-1-8B-Instruct', 'Baichuan3-Turbo', 'Qwen/Qwen2.5-Coder-32B-Instruct', 'glm-4-flash', 'moonshot-v1-8k-vision-preview', 'qwen-long', 'gemini-2.0-flash-search', 'microsoft/WizardLM-2-8x22B', 'Doubao-1.5-vision-pro-32k', 'Qwen/Qwen2.5-72B-Instruct-128K', 'deepseek-ai/DeepSeek-R1-Distill-Qwen-7B', 'gemini-1.5-flash-exp-0827', 'gemini-2.0-flash-thinking-exp-01-21', 'anthropic-3-5-sonnet-20240620', 'deepseek-ai/DeepSeek-R1-Zero', 'meta-llama/Llama-3.2-90B-Vision-Instruct', 'Qwen/QwQ-32B-Preview', 'Baichuan4', 'ahm-Phi-3-medium-4k', 'ahm-Phi-3-small-128k', 'grok-2-1212', 'ahm-Phi-3-5-MoE-instruct', 'deepseek-ai/DeepSeek-R1-Distill-Llama-8B', 'yi-large-turbo', 'deepseek-ai/DeepSeek-V2.5', 'gemini-2.0-flash-thinking-exp-1219', 'o3-mini', 'gemini-1.5-pro-exp-0827']\n"
     ]
    }
   ],
   "source": [
    "print(model_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d2a270-949c-4ad2-a568-e254e6231333",
   "metadata": {},
   "source": [
    "## Retrieve Model\n",
    "\n",
    "根据前面查询到当前支持的模型 ID 列表，获取指定模型实例，如`gpt-3.5-turbo`。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6fd7eca9-ed5a-4bca-8f9c-a0bf36177d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(base_url=\"https://aihubmix.com/v1\")\n",
    "\n",
    "# 将模型 ID 传入 retrieve 接口\n",
    "gpt_3 = client.models.retrieve(\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51078b58-67db-467a-b09f-ef40562f1fad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model(id='gpt-3.5-turbo', created=1626777600, object='model', owned_by='OpenAI', permission=[{'id': 'modelperm-LwHkVFn8AcMItP432fKKDIKJ', 'object': 'model_permission', 'created': 1626777600, 'allow_create_engine': True, 'allow_sampling': True, 'allow_logprobs': True, 'allow_search_indices': False, 'allow_view': True, 'allow_fine_tuning': False, 'organization': '*', 'group': None, 'is_blocking': False}], root='gpt-3.5-turbo', parent=None)\n"
     ]
    }
   ],
   "source": [
    "print(gpt_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67bd0916-d771-4745-85bb-28be33806d89",
   "metadata": {},
   "source": [
    "### 获取指定模型，如 GPT-4V\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ea16de8-add9-4ad4-b5b9-ebb959d7ab7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(id='gpt-4-vision-preview', created=1626777600, object='model', owned_by='OpenAI', permission=[{'id': 'modelperm-LwHkVFn8AcMItP432fKKDIKJ', 'object': 'model_permission', 'created': 1626777600, 'allow_create_engine': True, 'allow_sampling': True, 'allow_logprobs': True, 'allow_search_indices': False, 'allow_view': True, 'allow_fine_tuning': False, 'organization': '*', 'group': None, 'is_blocking': False}], root='gpt-4-vision-preview', parent=None)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.models.retrieve(\"gpt-4-vision-preview\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa107114-28cd-435a-a4b0-c9ceabddf415",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "028f4f7e-3be1-44d7-bfcd-c65a13e85093",
   "metadata": {},
   "source": [
    "# 文本内容补全初探（Completions API）[Legacy]\n",
    "\n",
    "使用 Completions API 实现各类文本生成任务\n",
    "\n",
    "主要请求参数说明：\n",
    "\n",
    "- **`model`** （string，必填）\n",
    "\n",
    "  要使用的模型的 ID。可以参考 **模型端点兼容性表**。\n",
    "\n",
    "- **`prompt`** （string or array，必填，Defaults to ）\n",
    "\n",
    "  生成补全的提示，编码为字符串、字符串数组、token 数组或 token 数组数组。\n",
    "\n",
    "  注意，这是模型在训练过程中看到的文档分隔符，所以如果没有指定提示符，模型将像从新文档的开头一样生成。\n",
    "\n",
    "- **`stream`** （boolean，选填，默认 false）\n",
    "\n",
    "  当它设置为 true 时，API 会以 SSE（ Server Side Event ）方式返回内容，即会不断地输出内容直到完成响应，流通过 `data: [DONE]` 消息终止。\n",
    "\n",
    "- **`max_tokens`** （integer，选填，默认是 16）\n",
    "\n",
    "  补全时要生成的最大 token 数。\n",
    "\n",
    "  提示 `max_tokens` 的 token 计数不能超过模型的上下文长度。大多数模型的上下文长度为 2048 个 token（最新模型除外，它支持 4096）\n",
    "\n",
    "- **`temperature`** （number，选填，默认是 1）\n",
    "\n",
    "  使用哪个采样温度，在 **0 和 2 之间**。\n",
    "\n",
    "  较高的值，如 0.8 会使输出更随机，而较低的值，如 0.2 会使其更加集中和确定性。\n",
    "\n",
    "  通常建议修改这个（`temperature` ）或 `top_p` 但两者不能同时存在，二选一。\n",
    "\n",
    "- **`n`** （integer，选填，默认为 1）\n",
    "\n",
    "  每个 `prompt` 生成的补全次数。\n",
    "\n",
    "  注意：由于此参数会生成许多补全，因此它会快速消耗 token 配额。小心使用，并确保对 `max_tokens` 和 `stop` 进行合理的设置。\n",
    "\n",
    "## 生成英文文本\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0526acb1-5741-48b6-ae64-917ad0d064b4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFoundError",
     "evalue": "Error code: 404 - {'error': {'message': 'This is a chat model and not supported in the v1/completions endpoint. Did you mean to use v1/chat/completions? (request id: 2025030803330737896604468383860)', 'type': 'invalid_request_error', 'param': 'model', 'code': None}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNotFoundError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mopenai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m OpenAI\n\u001b[32m      4\u001b[39m client = OpenAI(base_url=\u001b[33m\"\u001b[39m\u001b[33mhttps://aihubmix.com/v1\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m data = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompletions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m  \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgpt-3.5-turbo\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m  \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mSay this is a test\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m  \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m7\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m  \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\n\u001b[32m     11\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/jupyter_env/lib/python3.13/site-packages/openai/_utils/_utils.py:279\u001b[39m, in \u001b[36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    277\u001b[39m             msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[32m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    278\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[32m--> \u001b[39m\u001b[32m279\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/jupyter_env/lib/python3.13/site-packages/openai/resources/completions.py:539\u001b[39m, in \u001b[36mCompletions.create\u001b[39m\u001b[34m(self, model, prompt, best_of, echo, frequency_penalty, logit_bias, logprobs, max_tokens, n, presence_penalty, seed, stop, stream, stream_options, suffix, temperature, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    510\u001b[39m \u001b[38;5;129m@required_args\u001b[39m([\u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mprompt\u001b[39m\u001b[33m\"\u001b[39m], [\u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mprompt\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m    511\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m    512\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    537\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = NOT_GIVEN,\n\u001b[32m    538\u001b[39m ) -> Completion | Stream[Completion]:\n\u001b[32m--> \u001b[39m\u001b[32m539\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    540\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/completions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    541\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    542\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    543\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    544\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprompt\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    545\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mbest_of\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mbest_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    546\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mecho\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mecho\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    547\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfrequency_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    548\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogit_bias\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    549\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    550\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    551\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    552\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpresence_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    553\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    554\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    555\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    556\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    557\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msuffix\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msuffix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    558\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    559\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    560\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    561\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    562\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    563\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    564\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    565\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    566\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    567\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    568\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    569\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mCompletion\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    570\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/jupyter_env/lib/python3.13/site-packages/openai/_base_client.py:1242\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1228\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1229\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1230\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1237\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1238\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1239\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1240\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1241\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1242\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/jupyter_env/lib/python3.13/site-packages/openai/_base_client.py:919\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[39m\n\u001b[32m    916\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    917\u001b[39m     retries_taken = \u001b[32m0\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m919\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    920\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    921\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    922\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    923\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    924\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    925\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/jupyter_env/lib/python3.13/site-packages/openai/_base_client.py:1023\u001b[39m, in \u001b[36mSyncAPIClient._request\u001b[39m\u001b[34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[39m\n\u001b[32m   1020\u001b[39m         err.response.read()\n\u001b[32m   1022\u001b[39m     log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1023\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1025\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._process_response(\n\u001b[32m   1026\u001b[39m     cast_to=cast_to,\n\u001b[32m   1027\u001b[39m     options=options,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1031\u001b[39m     retries_taken=retries_taken,\n\u001b[32m   1032\u001b[39m )\n",
      "\u001b[31mNotFoundError\u001b[39m: Error code: 404 - {'error': {'message': 'This is a chat model and not supported in the v1/completions endpoint. Did you mean to use v1/chat/completions? (request id: 2025030803330737896604468383860)', 'type': 'invalid_request_error', 'param': 'model', 'code': None}}"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(base_url=\"https://aihubmix.com/v1\")\n",
    "\n",
    "data = client.completions.create(\n",
    "  model=\"gpt-3.5-turbo-instruct\",\n",
    "  prompt=\"Say this is a test\",\n",
    "  max_tokens=7,\n",
    "  temperature=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af7a8d1f-c2f7-421d-bd0d-0890d06a0c34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion(id='cmpl-B8fD8DuKJcJW4xitganB6HvZz4C8P', choices=[CompletionChoice(finish_reason='stop', index=0, logprobs=None, text='\\n\\nThis is a test.', content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1741404738, model='gpt-3.5-turbo-instruct', object='text_completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=6, prompt_tokens=5, total_tokens=11, completion_tokens_details=None, prompt_tokens_details=None), prompt_filter_results=[{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}])\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "63cddd0f-a8f3-4f62-891a-8146306a5d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = data.choices[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "49cbd498-bfa5-4d11-a6ee-30822b24dcc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "This is a test.\n"
     ]
    }
   ],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43d83bd-375f-4256-925a-e894d0e155a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159f1bf9-1604-414c-af74-45b22c33a7f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5c79be11-b2b4-4580-ad10-b7111cb950ea",
   "metadata": {},
   "source": [
    "## 生成中文文本\n",
    "\n",
    "调整 `max_tokens`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3a4018-7c72-49a1-942b-167c3941fb96",
   "metadata": {},
   "outputs": [
    {
     "ename": "BadRequestError",
     "evalue": "Error code: 400 - {'error': {'message': 'The completion operation does not work with the specified model, gpt-4o-mini. Please choose different model and try again. You can learn more about which models can be used with each operation here: https://go.microsoft.com/fwlink/?linkid=2197993. (request id: 2025030803500273704160591661553)', 'type': '', 'param': '', 'code': 'OperationNotSupported'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mBadRequestError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m data = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompletions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m  \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgpt-4o-mini\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m  \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m讲2个给程序员听得笑话\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m  \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m  \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.5\u001b[39;49m\n\u001b[32m      6\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/jupyter_env/lib/python3.13/site-packages/openai/_utils/_utils.py:279\u001b[39m, in \u001b[36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    277\u001b[39m             msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[32m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    278\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[32m--> \u001b[39m\u001b[32m279\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/jupyter_env/lib/python3.13/site-packages/openai/resources/completions.py:539\u001b[39m, in \u001b[36mCompletions.create\u001b[39m\u001b[34m(self, model, prompt, best_of, echo, frequency_penalty, logit_bias, logprobs, max_tokens, n, presence_penalty, seed, stop, stream, stream_options, suffix, temperature, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    510\u001b[39m \u001b[38;5;129m@required_args\u001b[39m([\u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mprompt\u001b[39m\u001b[33m\"\u001b[39m], [\u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mprompt\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m    511\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m    512\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    537\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = NOT_GIVEN,\n\u001b[32m    538\u001b[39m ) -> Completion | Stream[Completion]:\n\u001b[32m--> \u001b[39m\u001b[32m539\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    540\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/completions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    541\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    542\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    543\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    544\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprompt\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    545\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mbest_of\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mbest_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    546\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mecho\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mecho\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    547\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfrequency_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    548\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogit_bias\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    549\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    550\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    551\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    552\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpresence_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    553\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    554\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    555\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    556\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    557\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msuffix\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msuffix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    558\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    559\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    560\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    561\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    562\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    563\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    564\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    565\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    566\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    567\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    568\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    569\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mCompletion\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    570\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/jupyter_env/lib/python3.13/site-packages/openai/_base_client.py:1242\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1228\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1229\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1230\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1237\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1238\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1239\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1240\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1241\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1242\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/jupyter_env/lib/python3.13/site-packages/openai/_base_client.py:919\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[39m\n\u001b[32m    916\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    917\u001b[39m     retries_taken = \u001b[32m0\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m919\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    920\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    921\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    922\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    923\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    924\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    925\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/jupyter_env/lib/python3.13/site-packages/openai/_base_client.py:1023\u001b[39m, in \u001b[36mSyncAPIClient._request\u001b[39m\u001b[34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[39m\n\u001b[32m   1020\u001b[39m         err.response.read()\n\u001b[32m   1022\u001b[39m     log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1023\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1025\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._process_response(\n\u001b[32m   1026\u001b[39m     cast_to=cast_to,\n\u001b[32m   1027\u001b[39m     options=options,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1031\u001b[39m     retries_taken=retries_taken,\n\u001b[32m   1032\u001b[39m )\n",
      "\u001b[31mBadRequestError\u001b[39m: Error code: 400 - {'error': {'message': 'The completion operation does not work with the specified model, gpt-4o-mini. Please choose different model and try again. You can learn more about which models can be used with each operation here: https://go.microsoft.com/fwlink/?linkid=2197993. (request id: 2025030803500273704160591661553)', 'type': '', 'param': '', 'code': 'OperationNotSupported'}}"
     ]
    }
   ],
   "source": [
    "data = client.completions.create(\n",
    "  model=\"Qwen/QwQ-32B\",\n",
    "  prompt=\"讲5个给程序员听得笑话\",\n",
    "  max_tokens=1000,\n",
    "  temperature=0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f04959ba-5781-4e9e-bdfb-a55f0698acd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "当然，以下是五个适合程序员的笑话，希望你喜欢：\n",
      "\n",
      "---\n",
      "\n",
      "### 1. **二进制笑话**\n",
      "**程序员**走进一家酒吧， bartender 问：“要来杯什么？”  \n",
      "程序员回答：“给我一杯 10 进制的啤酒。”  \n",
      "bartender 一脸困惑：“你确定是 10 进制吗？”  \n",
      "程序员点头：“是的，10 进制。”  \n",
      "bartender 拿出一杯啤酒，程序员喝了一口，突然大喊：“等等，这杯啤酒有毒！”  \n",
      "bartender 笑着说：“别担心，我数到你的时候才给你下毒。刚才那杯是第 1 杯，而 10 在二进制里其实是 2，所以我还没到呢。”\n",
      "\n",
      "---\n",
      "\n",
      "### 2. **递归笑话**\n",
      "程序员对他的朋友说：“我最近学会了一种新的语言，叫‘递归’。”  \n",
      "朋友问：“听起来很有趣，你能举个例子吗？”  \n",
      "程序员回答：“当然，递归就是……呃……递归就是……呃……递归就是……”  \n",
      "（无限循环中）\n",
      "\n",
      "---\n",
      "\n",
      "### 3. **调试笑话**\n",
      "有一天，一个程序员在调试代码时，突然大喊：“我找到了！这个 bug 就在第 42 行！”  \n",
      "他的同事跑过来问：“真的吗？快告诉我怎么解决！”  \n",
      "程序员叹了口气：“不，我只是把它移到第 43 行，这样 bug 就在第 43 行了。”\n",
      "\n",
      "---\n",
      "\n",
      "### 4. **程序员的浪漫**\n",
      "程序员向女友求婚，女友问：“你愿意为我做任何事吗？”  \n",
      "程序员回答：“当然，只要给出时间复杂度和空间复杂度的保证。”  \n",
      "女友无奈：“我只想知道你愿不愿意和我结婚。”  \n",
      "程序员：“哦，这很简单，时间复杂度是 O(1)，空间复杂度也是 O(1)。我愿意。”\n",
      "\n",
      "---\n",
      "\n",
      "### 5. **程序员的咖啡**\n",
      "程序员走进咖啡店，点了一杯咖啡。  \n",
      "咖啡师问：“要加糖吗？”  \n",
      "程序员回答：“不用，我已经在代码里加了糖，现在我的咖啡是甜的。”  \n",
      "咖啡师一脸懵：“那你的咖啡现在是什么味道？”  \n",
      "程序员：“苦……等等，我是不是把糖放成了盐？”\n",
      "\n",
      "---\n",
      "\n",
      "希望这些笑话能让你会心一笑！ 😄💻\n",
      "\n",
      "---\n",
      "\n",
      "如果需要更多程序员相关的幽默，随时告诉我！😄\n",
      "\n",
      "---\n",
      "\n",
      "### 额外加送一个：\n",
      "**程序员和数学家的区别**  \n",
      "数学家走进一家酒吧， bartender 问：“要一杯吗？”  \n",
      "数学家说：“当然，给我一杯水。”  \n",
      "bartender 递过去，数学家喝了一口：“完美，这解决了我的渴。”  \n",
      "然后程序员走进来， bartender 问同样的问题，程序员说：“给我一杯水。”  \n",
      "bartender 递过去，程序员喝了一口，突然开始剧烈咳嗽，然后大喊：“这水里有毒！”  \n",
      "bartender 愕然：“不可能！我刚给数学家同样的水。”  \n",
      "程序员：“哦，那是因为你给数学家的是纯水，但给我加了递归！”\n",
      "\n",
      "（递归的笑话总是绕不开！）😄\n",
      "\n",
      "---\n",
      "\n",
      "程序员的世界，bug 是日常，递归是噩梦，而笑话是治愈代码的良药！💻✨\n",
      "\n",
      "---\n",
      "\n",
      "如果这些笑话不够，还可以试试下面这个：\n",
      "\n",
      "### 6. **程序员的宠物**\n",
      "程序员养了一只猫，猫的名字叫 `NullPointer`，因为每次它跑掉的时候，程序员都会说：“我的猫指针又指向了空！”\n",
      "\n",
      "---\n",
      "\n",
      "希望这些能带来一些欢乐！😄\n",
      "\n",
      "---\n",
      "\n",
      "### 7. **程序员的早餐**\n",
      "程序员早餐吃了两个鸡蛋和一个煎饼。  \n",
      "同事问他：“你吃了几个鸡蛋？”  \n",
      "程序员回答：“不确定，但煎饼的 hash 值是 `0x1a2b3c`。”  \n",
      "同事无语：“……”\n",
      "\n",
      "---\n",
      "\n",
      "### 8. **程序员的约会**\n",
      "程序员第一次约会，女生问：“你有什么爱好？”  \n",
      "程序员回答：“我擅长调试、重构和写单元测试。”  \n",
      "女生：“……那你的爱好是不是都是工作？”  \n",
      "程序员：“不，我最喜欢的爱好是修复 bug，但最近 bug 都太难了，我准备改学写 bug 了。”\n",
      "\n",
      "---\n",
      "\n",
      "这些笑话的核心是程序员的日常痛点和术语梗，希望你喜欢！😄\n",
      "\n",
      "---\n",
      "\n",
      "### 9. **程序员的哲学**\n",
      "程序员对朋友说：“我最近在思考人生的意义。”  \n",
      "朋友问：“你得出什么结论了吗？”  \n",
      "程序员回答：“人生就像递归，必须有一个 base case 否则就会无限循环。”  \n",
      "朋友：“……那 base case 是什么？”  \n",
      "程序员：“当我找到人生意义的时候，递归就会停止。”\n",
      "\n",
      "---\n",
      "\n",
      "### 10. **程序员的旅行\n"
     ]
    }
   ],
   "source": [
    "text = data.choices[0].text\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad54c353-64bf-44dc-ad55-1d2c4a783443",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3e5bdaff-764f-4fbf-b2c2-a8afbdaca8c6",
   "metadata": {},
   "source": [
    "## 生成 Python 代码，并执行和验证\n",
    "\n",
    "以面试中考察的典型的试题 `快速排序` 为例\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3d5a6a51-57cd-4890-8978-b07efa2c28e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = client.completions.create(\n",
    "  model=\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\n",
    "  prompt=\"生成可执行的快速排序 Python 代码\",\n",
    "  max_tokens=1000,\n",
    "  temperature=0\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "45e24e7d-72d7-491a-a60f-0e8031a6fc7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "，包含以下内容：\n",
      "- 生成一个随机的整数数组，包含10个元素。\n",
      "- 写一个快速排序的函数，包含以下参数：\n",
      "   - arr: 整数数组\n",
      "   - pivot: 可选参数，指定排序的基准元素\n",
      "- 写一个测试函数，测试快速排序的正确性，包含以下参数：\n",
      "   - arr: 整数数组\n",
      "   - expected: 整数数组\n",
      "- 生成一个包含10个元素的随机整数数组，作为测试用例。\n",
      "- 执行排序函数，并将结果存储在sorted_arr。\n",
      "- 检查排序是否正确。\n",
      "- 所有测试都必须在同一个测试函数中完成，不使用任何额外的函数或模块。\n",
      "- 请确保代码中的随机数生成是可复现的，即每次运行测试函数时，生成的数组都是相同的。\n",
      "- 请确保代码中的随机数生成是均匀分布的，即每个元素出现的概率相同。\n",
      "- 请确保代码中的随机数生成是独立的，即每次运行测试函数时，生成的数组都是独立的。\n",
      "- 请确保代码中的随机数生成是均匀分布的，即每个元素出现的概率相同。\n",
      "- 请确保代码中的随机数生成是独立的，即每次运行测试函数时，生成的数组都是独立的。\n",
      "- 请确保代码中的随机数生成是均匀分布的，即每个元素出现的概率相同。\n",
      "- 请确保代码中的随机数生成是独立的，即每次运行测试函数时，生成的数组都是独立的。\n",
      "- 请确保代码中的随机数生成是均匀分布的，即每个元素出现的概率相同。\n",
      "- 请确保代码中的随机数生成是独立的，即每次运行测试函数时，生成的数组都是独立的。\n",
      "- 请确保代码中的随机数生成是均匀分布的，即每个元素出现的概率相同。\n",
      "- 请确保代码中的随机数生成是独立的，即每次运行测试函数时，生成的数组都是独立的。\n",
      "- 请确保代码中的随机数生成是均匀分布的，即每个元素出现的概率相同。\n",
      "- 请确保代码中的随机数生成是独立的，即每次运行测试函数时，生成的数组都是独立的。\n",
      "- 请确保代码中的随机数生成是均匀分布的，即每个元素出现的概率相同。\n",
      "- 请确保代码中的随机数生成是独立的，即每次运行测试函数时，生成的数组都是独立的。\n",
      "- 请确保代码中的随机数生成是均匀分布的，即每个元素出现的概率相同。\n",
      "- 请确保代码中的随机数生成是独立的，即每次运行测试函数时，生成的数组都是独立的。\n",
      "- 请确保代码中的随机数生成是均匀分布的，即每个元素出现的概率相同。\n",
      "- 请确保代码中的随机数生成是独立的，即每次运行测试函数时，生成的数组都是独立的。\n",
      "- 请确保代码中的随机数生成是均匀分布的，即每个元素出现的概率相同。\n",
      "- 请确保代码中的随机数生成是独立的，即每次运行测试函数时，生成的数组都是独立的。\n",
      "- 请确保代码中的随机数生成是均匀分布的，即每个元素出现的概率相同。\n",
      "- 请确保代码中的随机数生成是独立的，即每次运行测试函数时，生成的数组都是独立的。\n",
      "- 请确保代码中的随机数生成是均匀分布的，即每个元素出现的概率相同。\n",
      "- 请确保代码中的随机数生成是独立的，即每次运行测试函数时，生成的数组都是独立的。\n",
      "- 请确保代码中的随机数生成是均匀分布的，即每个元素出现的概率相同。\n",
      "- 请确保代码中的随机数生成是独立的，即每次运行测试函数时，生成的数组都是独立的。\n",
      "- 请确保代码中的随机数生成是均匀分布的，即每个元素出现的概率相同。\n",
      "- 请确保代码中的随机数生成是独立的，即每次运行测试函数时，生成的数组都是独立的。\n",
      "- 请确保代码中的随机数生成是均匀分布的，即每个元素出现的概率相同。\n",
      "- 请确保代码中的随机数生成是独立的，即每次运行测试函数时，生成的数组都是独立的。\n",
      "- 请确保代码中的随机数生成是均匀分布的，即每个元素出现的概率相同。\n",
      "- 请确保代码中的随机数生成是独立的，即每次运行测试函数时，生成的数组都是独立的。\n",
      "- 请确保代码中的随机数生成是均匀分布的，即每个元素出现的概率相同。\n",
      "- 请确保代码中的随机数生成是独立的，即每次运行测试函数时，生成的数组都是\n"
     ]
    }
   ],
   "source": [
    "text = data.choices[0].text\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c6675c-611e-4933-9fca-804200eef339",
   "metadata": {},
   "source": [
    "#### Prompt：Jupyter Notebook 中执行生成的代码\n",
    "\n",
    "Prompt：\n",
    "\n",
    "```\n",
    "我现在用 Completion API 生成了 Python 代码，并以字符串形式存放在 text 中，如下所示：\n",
    "\n",
    "text = data.choices[0].text\n",
    "print(text)\n",
    "\n",
    "def quick_sort(arr):\n",
    "    if len(arr) <= 1:\n",
    "        return arr\n",
    "    pivot = arr[0]\n",
    "    left = [x for x in arr[1:] if x <= pivot]\n",
    "    right = [x for x in arr[1:] if x > pivot]\n",
    "    return quick_sort(left) + [pivot] + quick_sort(right)\n",
    "\n",
    "如何在 Jupyter notebook 中执行text中存放的这段代码\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "21707523-bde6-48b9-ac9d-da693045f7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# `exec` 函数会执行传入的字符串作为 Python 代码。\n",
    "# 在这个例子中，我们使用 `exec` 来定义了一个 `quick_sort` 函数，然后你就可以调用这个函数了。\n",
    "# 请注意，`exec` 可以执行任何 Python 代码，因此在使用它的时候一定要小心，特别是当你执行的代码来自不可信的来源时。\n",
    "exec(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "15918392-560b-4826-8800-4c7a11167579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 2, 3, 6, 8, 10, 12]\n"
     ]
    }
   ],
   "source": [
    "# 现在你可以调用这个函数了\n",
    "print(quick_sort([12,3,6,8,10,1,2,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd669a78-125f-478f-b3d9-677f137d9398",
   "metadata": {},
   "source": [
    "# 聊天机器人初探（Chat Completions API）\n",
    "\n",
    "使用 Chat Completions API 实现对话任务\n",
    "\n",
    "聊天补全(Chat Completions API)以消息列表作为输入，并返回模型生成的消息作为输出。尽管聊天格式旨在使多轮对话变得简单，但它同样适用于没有任何对话的单轮任务。\n",
    "\n",
    "主要请求参数说明：\n",
    "\n",
    "- **`model` （string，必填）**\n",
    "\n",
    "  要使用的模型 ID。有关哪些模型适用于 Chat API 的详细信息\n",
    "\n",
    "- **`messages` （array，必填）**\n",
    "\n",
    "  迄今为止描述对话的消息列表\n",
    "\n",
    "  - **`role` （string，必填）**\n",
    "\n",
    "  发送此消息的角色。`system` 、`user` 或 `assistant` 之一（一般用 user 发送用户问题，system 发送给模型提示信息）\n",
    "\n",
    "  - **`content` （string，必填）**\n",
    "\n",
    "    消息的内容\n",
    "\n",
    "  - **`name` （string，选填）**\n",
    "\n",
    "    此消息的发送者姓名。可以包含 a-z、A-Z、0-9 和下划线，最大长度为 64 个字符\n",
    "\n",
    "- **`stream` （boolean，选填，是否按流的方式发送内容）**\n",
    "\n",
    "  当它设置为 true 时，API 会以 SSE（ Server Side Event ）方式返回内容。SSE 本质上是一个长链接，会持续不断地输出内容直到完成响应。如果不是做实时聊天，默认 false 即可。\n",
    "\n",
    "- **`max_tokens` （integer，选填）**\n",
    "\n",
    "  在聊天补全中生成的最大 **tokens** 数。\n",
    "\n",
    "  输入 token 和生成的 token 的总长度受模型上下文长度的限制。\n",
    "\n",
    "- **`temperature` （number，选填，默认是 1）**\n",
    "\n",
    "  采样温度，在 0 和 2 之间。\n",
    "\n",
    "  较高的值，如 0.8 会使输出更随机，而较低的值，如 0.2 会使其更加集中和确定性。\n",
    "\n",
    "  通常建议修改这个（`temperature` ）或者 `top_p` ，但两者不能同时存在，二选一。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00108e4-b98e-4d55-a1e2-78845b321fec",
   "metadata": {},
   "source": [
    "## 开启聊天模式\n",
    "\n",
    "使用 `messages` 记录迄今为止对话的消息列表\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "172f2eb6-2d2b-4d10-9887-5e4af011c77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(base_url=\"https://aihubmix.com/v1\")\n",
    "\n",
    "messages=[\n",
    "    {\n",
    "        \"role\": \"user\", \n",
    "        \"content\": \"Hello!\"\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "data = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages = messages\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "158a8a3b-0a73-4157-9025-8282527fd692",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-B8fbYTWgck1YyYyqLsXgGEaJPdvvt', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Hello! How can I assist you today?', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1741406252, model='gpt-3.5-turbo-0125', object='chat.completion', service_tier=None, system_fingerprint='fp_0165350fbb', usage=CompletionUsage(completion_tokens=9, prompt_tokens=9, total_tokens=18, completion_tokens_details=None, prompt_tokens_details=None))\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d872f47e-b768-4d3e-850f-c2034e2e2263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content='Hello! How can I assist you today?', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "# 从返回的数据中获取生成的消息\n",
    "new_message = data.choices[0].message\n",
    "# 打印 new_message\n",
    "print(new_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ee8c6048-2fed-4a81-90cc-45f526630aad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'role': 'user', 'content': 'Hello!'}, ChatCompletionMessage(content='Hello! How can I assist you today?', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None)]\n"
     ]
    }
   ],
   "source": [
    "# 将消息追加到 messages 列表中\n",
    "messages.append(new_message)\n",
    "print(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1f88a3a6-c6ad-47a2-a187-40f4e921b54f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "openai.types.chat.chat_completion_message.ChatCompletionMessage"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(new_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4dc4a02b-2c19-4114-bfad-7b8364d1f8fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'assistant'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_message.role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "843e1454-85b9-409f-8a6a-c84fadcab05a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello! How can I assist you today?'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "626586e5-55c0-4b1c-8dc4-175edab9b7c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletionMessage(content='Hello! How can I assist you today?', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bbf5b445-f0b2-422c-befd-2738982903d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'role': 'user', 'content': 'Hello!'}]\n"
     ]
    }
   ],
   "source": [
    "print(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9d6f7b-09fd-4bed-bcde-2ab50d3d415c",
   "metadata": {},
   "source": [
    "#### Prompt: OpenAIObject -> Dict\n",
    "\n",
    "```\n",
    "打印 messages 列表后发现数据类型不对，messages 输出如下：\n",
    "\n",
    "print(messages)\n",
    "\n",
    "[{'role': 'user', 'content': 'Hello!'}, <OpenAIObject at 0x7f27582c13f0> JSON: {\n",
    "  \"content\": \"Hello! How can I assist you today?\",\n",
    "  \"role\": \"assistant\"\n",
    "}]\n",
    "\n",
    "将OpenAIObject 转换为一个如下数据类型格式：\n",
    "\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Hello!\"\n",
    "    }\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8d9052f8-88ef-4b71-8fa8-42bff7304537",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_message = data.choices[0].message\n",
    "new_message_dict = {\"role\": new_message.role, \"content\": new_message.content}\n",
    "type(new_message_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "699416f3-ee26-432a-8ad5-27b151f24846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'role': 'assistant', 'content': 'Hello! How can I assist you today?'}\n"
     ]
    }
   ],
   "source": [
    "print(new_message_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7a11a2c6-3f2b-4c35-b987-f396f839da7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将消息追加到 messages 列表中\n",
    "messages.append(new_message_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "532671cb-6ceb-472f-98c8-c86a38c08bc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'role': 'user', 'content': 'Hello!'}, {'role': 'assistant', 'content': 'Hello! How can I assist you today?'}]\n"
     ]
    }
   ],
   "source": [
    "print(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a5d741-5b2e-4f1a-8a74-e3b559874079",
   "metadata": {},
   "source": [
    "#### 新一轮对话\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ad2e089b-ba80-477b-92d1-c183f11082c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_chat = {\n",
    "    \"role\": \"user\",\n",
    "    \"content\": \"1.讲一个程序员才听得懂的冷笑话；2.今天是几号？3.明天星期几？\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "780f361d-b9e1-4343-8851-089d4c0aecde",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages.append(new_chat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "32b195bb-52ca-4b7f-a1f6-5b183ffbd58f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'content': 'Hello!', 'role': 'user'},\n",
      " {'content': 'Hello! How can I assist you today?', 'role': 'assistant'},\n",
      " {'content': '1.讲一个程序员才听得懂的冷笑话；2.今天是几号？3.明天星期几？', 'role': 'user'}]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "pprint(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "54b0532a-0099-40e3-8a3d-9dc72d6eccbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=messages\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "edad9b8d-2b46-4cd4-ba03-51c96cc4c175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content='1. 为什么程序员喜欢买冰淇淋？因为他们喜欢“冰”啊！\\n2. 今天是几号？很抱歉，我无法提供实时日期信息。\\n3. 明天是星期几？同样，我无法提供准确的明天日期信息。您可以查看手机或者其他工具来确认。有什么其他问题我可以帮助您解决吗？', role='assistant', function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "new_message = data.choices[0].message\n",
    "# 打印 new_messages \n",
    "print(new_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bedc91c2-4216-4686-b66c-df012a9778c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. 为什么程序员喜欢买冰淇淋？因为他们喜欢“冰”啊！\n",
      "2. 今天是几号？很抱歉，我无法提供实时日期信息。\n",
      "3. 明天是星期几？同样，我无法提供准确的明天日期信息。您可以查看手机或者其他工具来确认。有什么其他问题我可以帮助您解决吗？\n"
     ]
    }
   ],
   "source": [
    "# 打印 new_messages 内容\n",
    "print(new_message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877f2ff6-8bac-43a9-a827-e472c5698ed4",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903ec93e-fba9-403e-bfe4-b749f91abb0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7f417580-7810-4f0e-ad5c-6d2e0f9e7f42",
   "metadata": {},
   "source": [
    "## 使用多种身份聊天对话\n",
    "\n",
    "目前`role`参数支持 3 类身份： `system`, `user` `assistant`:\n",
    "\n",
    "![](images/chat_completion_api.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0981fe4b-410d-4d70-b07c-78a88e46b7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构造聊天记录\n",
    "messages=[\n",
    "    {\"role\": \"system\", \"content\": \"你是一个乐于助人的体育界专家。\"},\n",
    "    {\"role\": \"user\", \"content\": \"2008年奥运会是在哪里举行的？\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7d135caf-b778-4d50-b738-a429398c6eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "data = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=messages\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e97b0145-af2f-47bb-865f-9b2a8f4e6353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2008年夏季奥运会在中国北京举行。\n"
     ]
    }
   ],
   "source": [
    "message = data.choices[0].message.content\n",
    "print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fd56c185-b6e0-4ade-8236-9e2549182ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 添加 GPT 返回结果到聊天记录\n",
    "messages.append({\"role\": \"assistant\", \"content\": message})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a860210e-be0d-468e-8845-8ffceaecb034",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system', 'content': '你是一个乐于助人的体育界专家。'},\n",
       " {'role': 'user', 'content': '2008年奥运会是在哪里举行的？'},\n",
       " {'role': 'assistant', 'content': '2008年夏季奥运会在中国北京举行。'}]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "99bae857-2854-4090-8a4d-8e1930f70464",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 第二轮对话\n",
    "messages.append({\"role\": \"user\", \"content\": \"1.金牌最多的是哪个国家？2.奖牌最多的是哪个国家？\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f07bbb71-fe19-4582-b1f3-3ee994fcec0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system', 'content': '你是一个乐于助人的体育界专家。'},\n",
       " {'role': 'user', 'content': '2008年奥运会是在哪里举行的？'},\n",
       " {'role': 'assistant', 'content': '2008年夏季奥运会在中国北京举行。'},\n",
       " {'role': 'user', 'content': '1.金牌最多的是哪个国家？2.奖牌最多的是哪个国家？'}]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a138da7f-b5b3-40a1-b30b-4e6b0c8e249f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=messages\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f531bc4d-3eeb-49f7-b717-0986f2b4af2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. 2008年夏季奥运会中，金牌最多的国家是中国，共获得51枚金牌。\n",
      "2. 2008年夏季奥运会中，奖牌最多的国家是中国，共获得100枚奖牌（51枚金牌、21枚银牌、28枚铜牌）。\n"
     ]
    }
   ],
   "source": [
    "message = data.choices[0].message.content\n",
    "print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3500811e-3a80-4ed0-9770-a1f761dfab6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[{'role': 'user', 'content': '1.金牌最多的是哪个国家？2.奖牌最多的是哪个国家？'}]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cd59b92d-8362-4215-8865-82fe5cafce56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1. 根据2021年东京奥运会的数据，金牌最多的国家是美国。\\n\\n2. 根据2021年东京奥运会的数据，奖牌最多的国家是美国。'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25220ddb-b894-41b0-a36f-aadfc18d1b23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Jupyter)",
   "language": "python",
   "name": "jupyter_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
